语音识别综述    

    

    













姓名：     张亚楠         

学号：  117106021921      

  

  

    

    

 2017  年  11  月







语音助手的研究及产业应用情况

摘要

随着人工智能的发展，语音助手作为人工智能领域的一个研究内容也已经由最初简单的模式匹配发展到今天这样越来越智能化的利用多种技术来进行与用户的交互，且主要是智能手机端的语音助手，作为一款智能型的手机应用，通过智能对话与即时问答的智能交互，实现帮忙用户解决问题，主要作用是帮忙用户解决生活类问题，通过语音交互来实现或替代部分我们在手机上的查询与操作应用，大大提高了不同场景下操作手机的便利性。比如我们在打电话的时候需要搜索联系人，这属于语音助手应用拨号的范畴，这时我们只需要打开手机的语音助手，对准语音助手说出联系人姓名即可，如果声音比较小，它会自动反馈一句“没有听清联系人”，现在语音助手的发展比较迅速，对于用户的生活类服务越来越人性化，不仅能语音识别中文，也可以识别一些简单的英文，百度AI中的语音识别可以识别中英文、粤语、广东话四种，不过作为语音机器人，还是会有一些功能上的局限性，比如会产生一些答非所问的回复。当下认知度较高的语音助手产品包括：苹果Siri，谷歌Google Now,微软Cortana，科大讯飞的灵犀语音助手，苹果手机中的siri开创了智能语音助手的先河，也是相对来说比较智能的。本文主要对语音助手研发过程中的语音识别技术进行相关研究。

2.研究的主要内容及意义

所谓的语音助手，主要是能帮助用户进行生活类服务，比如EMUI8.0的AI语音助手小E，比以往语音识别率更高，结果也会更准确点，用户可以通过对话让手机优化系统加速性能、调整音量、打开护眼模式、让手机打开蓝牙接收文件的文件夹等，如果在家不知道手机放在哪里的时候，还可以大喊让手机给用户一个回应，其中的语音唤醒功能会让手机听到呼喊以后产生震动并且响铃，以告诉你它的位置。

我们之所以会觉得语音助手可以智能的与用户进行交互，背后是需要很多相关技术来支持的：机器学习（深度神经网络）和数据挖掘算法、语音识别、语义分析和理解、语音交互，并需要语音知识数据库进行云端支持。

那么其中的语音识别，就是将人类说话的内容和用意转换为计算机可以读懂的输入，并且从语音数据库中搜索与之最为匹配的回答反馈给用户。我们通过对当前市场上语音识别技术的分析来确定本文研究的主要内容是通过现如今比较火的基于深度学习技术进行语音识别。对语音识别进行深入研究具有很好的意义，因为用户的语音必须能够被语音助手产品很好的识别才能进行接下来的工作，而现在市场上的语音助手产品，不管是苹果Siri,还是微软Cortana，虽然已经相对智能，但是都不是特别成熟，所以我们就其中的语音识别技术进行探析，因为语音识别是整个智能语音系统中的入口，做不到好的语音识别就没办法开展之后的工作，所以语音识别性能的好坏决定了整个智能语音交互系统的用户满意度，那么本文就语音识别方面的主要内容、基本原理、应用的技术等展开论述。 

3.国内外研究现状及发展水平

语音识别作为人工智能领域和机器学习方面的一个比较具有研究意义的研究方向，最早的基于电子计算机的语音识别系统是由AT&T贝尔实验室开发的Audrey语音识别系统，它能够识别10个英文数字。其识别方法是跟踪语音中的共振峰，该系统得到了98%的正确率。到1950年代末，伦敦学院的Denes已经将语法概率加入语音识别中。

1960年代，人工神经网络被引入了语音识别。这一时代的两大突破是线性预测编码Linear Predictive Coding (LPC)，及动态时间规整Dynamic Time Warp技术。

语音识别技术的最重大突破是隐马尔科夫模型（Hidden Markov Model）的应用。从Baum提出相关数学推理，经过Labiner等人的研究，卡内基梅隆大学的李开复最终实现了第一个基于隐马尔科夫模型的大词汇量语音识别系统Sphinx。此后严格来说语音识别技术并没有脱离HMM框架。

2011年，苹果发布搭载语音助手产品Siri的iphone 4s，随后，Google研发出Google Now，以及微软研究院研发的微软小娜，百度研发的百度助手，科大讯飞研发的灵犀语音助手等。

所以可以说，基于语音识别的语音助手产品是从2010年开始迅速受到众多科研院所和大公司的青睐的。

在过去一年里，在语音识别方面有一些比较好的发展，美国微软雷德蒙研究院在电话语音识别的标准库Switchboard上报道达到5.9%的错误率，而在这个库上人类也只能达到大概5.9%，所以说机器的性能已经和人类基本达到了持平；国际语音通信联合会报道的CHIME4国际多通道语音分离和识别大赛，可以简单认为这是一个在限定词表和场景下的带噪的语音识别挑战赛，最好的系统性能报道达到了将近2%的错误率；在有关中文的研究方面，百度、搜狗、讯飞进行了连续三场的发布会，他们各自都展示了语音交互相关的一些系统，并且他们均表示通用领域下的识别性能达到97%。但是这些并不能说明继续研究语音识别技术变得毫无意义，即使智能语音交互系统已经达到如此好的性能，但是以上是对于特定任务和特定场景下的智能语音交互系统，而实际在用户的使用中，我们常常会面临不同的环境、不同的说话人、不同性能的设备，说话人方面，我们不同的人有不同的口音，来自不同的方言区，说话的时候又有不同的方式，同时我们在说话的时候运用不同的情感，我们真实的环境是非常复杂的，包括各种各样的噪声，包括汽车喇叭声、飞机的噪声、马路上人的声音，还有一些会场的回声等等；设备方面，我们可以用手持麦克风、领夹麦克风、耳戴麦克风、近场远场的麦克风等等。此外在真实的实际应用场景下，往往是这三个因素叠加在一起的，使得整个的影响变得更加的复杂，所以如何设计一套鲁棒的性能好的语音识别系统，来很好的处理这些不确定性，也是非常具有挑战性的。

4.算法原理、技术路线的分析与比较

语音识别系统的本质是一个模式识别系统，包括特征提取、模式匹配、参考模式库等三个基本单元。

目前具有代表性的语音识别方法主要有动态时间规整技术（DTW）、隐马尔可夫模型（HMM）、矢量量化（VQ）、人工神经网络（ANN）、支持向量机（SVM）等方法。

动态时间规整算法（Dynamic Time Warping，DTW）是在非特定人语音识别中一种简单有效的方法，该算法基于动态规划的思想，解决了发音长短不一的模板匹配问题，是语音识别技术中出现较早、较常用的一种算法。在应用DTW算法进行语音识别时，就是将已经预处理和分帧过的语音测试信号和参考语音模板进行比较以获取他们之间的相似度，按照某种距离测度得出两模板间的相似程度并选择最佳路径。

隐马尔可夫模型（HMM）是语音信号处理中的一种统计模型，是由Markov链演变来的，所以它是基于参数模型的统计识别方法。由于其模式库是通过反复训练形成的与训练输出信号吻合概率最大的最佳模型参数而不是预先储存好的模式样本，且其识别过程中运用待识别语音序列与HMM参数之间的似然概率达到最大值所对应的最佳状态序列作为识别输出，因此是较理想的语音识别模型。

矢量量化（Vector Quantization）是一种重要的信号压缩方法。与HMM相比，矢量量化主要适用于小词汇量、孤立词的语音识别中。其过程是将若干个语音信号波形或特征参数的标量数据组成一个矢量在多维空间进行整体量化。把矢量空间分成若干个小区域，每个小区域寻找一个代表矢量，量化时落入小区域的矢量就用这个代表矢量代替。矢量量化器的设计就是从大量信号样本中训练出好的码书，从实际效果出发寻找到好的失真测度定义公式，设计出最佳的矢量量化系统，用最少的搜索和计算失真的运算量实现最大可能的平均信噪比。

在实际的应用过程中，人们还研究了多种降低复杂度的方法，包括无记忆的矢量量化、有记忆的矢量量化和模糊矢量量化方法。

人工神经网络（ANN）是20世纪80年代末期提出的一种新的语音识别方法。其本质上是一个自适应非线性动力学系统，模拟了人类神经活动的原理，具有自适应性、并行性、鲁棒性、容错性和学习特性，其强大的分类能力和输入—输出映射能力在语音识别中都很有吸引力。其方法是模拟人脑思维机制的工程模型，它与HMM正好相反，其分类决策能力和对不确定信息的描述能力得到举世公认，但它对动态时间信号的描述能力尚不尽如人意，通常MLP分类器只能解决静态模式分类问题，并不涉及时间序列的处理。尽管学者们提出了许多含反馈的结构，但它们仍不足以刻画诸如语音信号这种时间序列的动态特性。由于ANN不能很好地描述语音信号的时间动态特性，所以常把ANN与传统识别方法结合，分别利用各自优点来进行语音识别而克服HMM和ANN各自的缺点。近年来结合神经网络和隐含马尔可夫模型的识别算法研究取得了显著进展，其识别率已经接近隐含马尔可夫模型的识别系统，进一步提高了语音识别的鲁棒性和准确率。

支持向量机（Support vector machine）是应用统计学理论的一种新的学习机模型，采用结构风险最小化原理（Structural Risk Minimization，SRM），有效克服了传统经验风险最小化方法的缺点。兼顾训练误差和泛化能力，在解决小样本、非线性及高维模式识别方面有许多优越的性能，已经被广泛地应用到模式识别领域。

那么基于以上对语音识别系统原理和语音识别的方法分析来看，传统的语音识别和目前以深度学习为主的语音识别在流程和技术上有哪些不同呢？

传统的语音识别是应用数学工具即统计的语音识别，它是由四个概率模型来对用户的语音进行解码识别的，分别是：

1.特征提取P（A|O）：将原始的语音通过信号处理转换成特征向量序列，去除噪声和其他无关信息；

2.声学模型P（O|L）：这也是一个概率模型，可以描述不同声音的各种不同特性，这是语音识别最关键的技术之一，用户刻画不同语音单元，比如音节、字、词，而在这项技术中应用广泛的模型是隐马尔科夫模型（HMM），这个HMM可以认为是一个基本的有限状态传输机，可以把一个表示语音的特征向量序列通过有限状态机转换成状态机的状态序列，包括音素、音节、字、词等；

3.字典模型P(L|W)：它是声学模型和语言模型的一个桥梁，主要作用就是在词和声学单元之间定义一个映射，即单词所对应的语言之间存在着一种怎样的映射或者说对应关系，既可以是一个确定化的模型也可以是一个概率模型；

4.语言模型P(W)：它是在给定历史的条件下来预测下一个词的概率，可以很好的引导搜索算法，消除声学单元之间的混淆性，特别是声学相似的单元，比如 great wine和great twine，假如没有语言模型，单有声学模型是有可能出错误的，所以语言模型是很重要的存在，它这个模型的应用也很广，比如性能最好的商用语音识别所采用的语言模型是N-gram的语言模型，此外还有比较火的基于深度学习、基于神经网络的语言模型。

在这四个概率的引导下，通过最优化的方法将最后的识别结果给找出来，根据相关算法的不同可以分为如下的种类，包括动态的、静态的解码器，以及深度优先或者广度优先，以及单便利和多便利解码器等等，目前大部分商用系统采用的是静态的、广度优先的、多便利解码算法。

传统的语音识别需要经过前端的信号处理、特征提取、声学模型、语言模型各个模块的优化，来实现整个系统的识别。那么相比较之下深度学习出来以后语音识别技术方面有了哪些不同或者说又做了哪些新的内容呢？

基于深度学习的第一代的语音识别系统，是将传统的特征提取模块和声学建模模块变成了DNN这部分，它将传统的声学模型中基于浅层的高斯混合模型替换成了现在的深度神经网络模型，通过深度神经网络模型的多层的非线性建模能力直接预测状态之间的分布函数，同时不需要像传统方法一样进行基于人工的细致调节的特征的提取，他通过自身的深度模型的特征引擎能力，就可以从比较原始的语音信号中提取比较具有鉴别能力的特征。

基于DNN-HMM的连续语音识别可以使用TIMIT语音库进行实验，TIMIT语音库是为进行声学、语音学、自动语音识别的研究而设计的英语语料库，主要由630个人的语音数据组成，这些说话人来自美国的8个不同方言区。同时它还自带有发音字典。比如应用以上技术所研发的Kaldi语音识别工具，是一个基于C++语言的语音识别软件，遵从Apache License2.0开源协议，

更强大的深度神经网络也被应用于语音识别，包括卷积神经网络，它可以对平移不变性和局部刻划进行很好的建模，此外对长时信息建模能力比较强的递归神经网络，以及在这个基础上派生出来的长短时记忆模型等等，在这些模型的基础上各种组合模型也被提出，包括谷歌提出CLD模型，也就是所谓的卷积神经网络加上递归神经网络加上全连接网络的神经网络组合模式，它可以利用各个神经网络的优势可以进一步的提升性能。

在国内关于语音识别研究的进展来说，百度使用的是一个所谓CLD的模型，就是前面所说的卷积神经网络加递归神经网络加全连接神经网络组合的模型，科大讯飞采用的是一个所谓FSMNN的一个模型，可以简单的理解成它介于递归和前馈神经网络的之间的模型，它可以既像递归神经网络一样，对长时信息进行很好的建模，同时又用前馈神经网络快速计算的一个优势。

那么应用比较广泛的神经网络算法就是BP神经网络算法（反向神经网络算法），它由三层组成：输入层、隐含层、输出层，每层之间都由神经元连接而成，每一层的输入是上一层的输出，在输入数据之后经过一个线性函数然后到达隐含层，再通过计算每个神经元的权重经过非线性激励函数进行相应的输出。

在BP算法中，以三层神经网络为例，即只有输入层、一个隐含层、输出层，输入的是一个向量记为X={，隐含层的输出为Y={

,表示隐含层的偏置，这里偏置可以理解为权重，输出结果向量为O={,表示输出层的偏置，输入层到隐含层的权值矩阵为V={,其中表示所有输入层的神经元到隐含层的第J个神经元对应的权值向量。隐层到输出层的权重矩阵为W={,列向量为隐含层中所有神经元到输出层中第k个神经元的权值向量。那么非线性激励函数可以使用S型函数（sigmoid函数）。但是基于BP神经网络的算法也有一定的局限性，即连接中的权重的计算问题，计算的误差下降的是否明显，而这些也与激励函数有关。

那么以上是三层的BP神经网络，还不是深度神经网络，我们可以把具有输入层、多于一层的隐含层和输出层成为深度神经网络，在语音识别研究中，DAE（深度自动编码器）深度神经网络也是一种进行研究语音识别的不错的技术，它本来是Rumelhart为了处理高维复杂的数据，提出了自动编码的概念，后来，Hinton等人对原型自动编码器结构进行改进，用贪婪逐层训练算法完成对隐含层的训练，然后利用BP算法对整个网络进行精调，有效的改善了传统神经网络的不足之处。AE是一种前向传播神经网络，要求网络的输出值等于输入值，这里不予细致的介绍，只对BP神经网络进行介绍。

5.应用场景和应用水平的分析与比较

语音识别作为人工智能领域最先发展起来的，其所应用到的方面是很广泛的，不仅是语音助手产品开发中的入口和核心，也是其他应用场景的重要一关，但是正如前面所说的，在语音助手方面语音识别还有很大的研究价值，不仅要考虑说话人的内容和方言，还有人声及其他声音干扰、近场远场识别等因素，以科大讯飞2015年提出的AIUI为例，它旨在解决上述问题并且希望能在人工智能时代提供一种智能的人机交互界面，AIUI提供远场唤醒和识别降噪的方案，同时还兼容全国将近17种方言，这已经是相当不错的智能语音交互系统了。

在其他方面，语音识别技术占据重要地位，基于声纹识别的通用语音控制系统，随着物联网的发展，对家电的智能控制可以方便人们的生活，可以把语音控制和安全控制结合起来，那么系统就会变的更自然更人性化。

应用到智能家居中，现在很多家庭都会需要红外遥控器控制家电，但是由于红外线传输受到空间位置的影响，那么为了解决这样的问题，可以设计一个将多个遥控设备集于一体并且通过声音来控制它常用功能的集成设备，这样不管用户的空间位置怎么样都可以通过语音来控制设备的开关和使用问题，那么在这个智能家居系统中语音识别就是一个不可或缺的重要技术。

现代生活中，很多人都购买私家车，那么司机在行车途中如果需要接打重要电话，那么单手开车或者低头拿手机放手机就会很容易发生交通事故，这时候如果在私家车上安装一款智能语音系统，司机在接电话或者打电话的时候只需要说话就行，这个系统也是必须要用到语音识别技术的。

在自然语言处理方面，语音识别技术也是很重要的，比如在医疗领域，要想让机器听懂患者所描述的症状然后自动去搜索相关词和治疗的方案，这是比较由难度的，因为汉语的博大精深以及说话人的内容与口音不同，所以识别起来会有一定难度。

语音识别所应用到的行业非常广，而且有些与我们用户都息息相关，这里只介绍以上几种。

6.总结

基于以上对语音识别技术的介绍与分析，我们可以更加直观的看到语音识别领域目前的发展水平，对语音识别的研究仍然具有很大的价值，尽管很多语音识别系统的准确率已经达到很高，但是仍有很多需要继续研究的课题，如何更好的在有噪音干扰的情况下准确识别出说话人的话、当距离语音助手产品远的时候如何更好地识别等等问题，那么未来的语音识别工作也可以在诸如上面两个方向展开，其他的比如利用深度学习的方法去研究语音识别也是一个研究方向。