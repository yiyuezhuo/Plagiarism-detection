人工智能原理与方法



图像识别的研究及产业应用情况







姓名：陈明玥

学号：117106021876

学院：计算机科学与工程学院















2017年11月





图像识别的研究及产业应用情况



1、研究的主要内容和意义

图像识别是人工智能的一个重要的领域。图像识别就是把一种研究对象根据其某些特征进行识别并分类，对数字图像进行区分的实质就是对图像进行模式识别。图像识别技术作为计算机视觉中的一个重要的研究领域，近些年广泛的应用于很多领域，如安全监控、军事侦察、产品检测、人机交互和医学等多个方面。图像识别的一般技术思路是从大量包含目标图片数据集中学习并抽取整体特征，如面积、周长、不变矩和傅立叶描绘子等，并采用统计分类技术进行目标分类。图像识别技术是以图像的主要特征为基础的，在图像识别过程中，必须排除多余的信息提取出有用的特征。图像识别的发展经历了三个阶段：文字识别、图像处理和识别及物体识别。

在进行图像识别时，首先要对获得图像信息进行预处理以滤去干扰、噪声、作几何、色彩校正等。图像处理包括图像编码、图像增强、图像压缩、图像复原、图像分割等。图像预处理的过程包括采用数字图像处理的各种方法来消除原始图像的噪声和畸变，消减无关特征而加强图像的系统感兴趣的特征，如果图像包含多个目标的，还要对图像进行分割，将其分为多个每个只包含一个目标的区域。第二部分是图像的特征提取，通常表现为减少特征的维数或局部特征的提取。最后是判决或者分类。即依据所提取的特征将前一部分的特征向量空间映射到类型空间，把图像归属已知的一类模式。

在图像识别过程中，图像处理是十分重要的一步。数字图像处理主要研究的内容有以下几方面。1)图像变换由于图像阵列很大，直接在空间域进行处理，涉及的计算量很大。因此往往采用各种图像变换的方法，如傅立叶变换(在频域中进行数字滤波处理)、沃尔什变换、离散余弦变换等空间处理技术，将空间域的处理转换为变换域处理，不仅可以减少计算量，而且可以获得更有效的处理。目前新兴研究的小波变换在时域和频域中都具有良好的局部化特性，在图像处理中也有着广泛而有效的应用。2)图像编码压缩技术可减少描述图像的数据量即比特数，以便节省图像传输、处理时间和减少所占用的存储器容量。压缩可以在不失真的前提下获得，也可以允许在失真的条件下进行。3)图像增强和图像复原是为了提高图像的质量，如去除噪声、提高图像的清晰度等。图像增强不考虑图像降质的原因，突出图像中所感兴趣的部分。如强化图像高频分量，可以使图像中物体轮廓清晰，细节明显；如强化低频分量可以减少图像中噪声影响。图像复原根据降质过程建立“降质模型”，再采用某种滤波方法，恢复或重建原来的图像。4)图像分割是数字图像处理中的关键技术之一。图像分割是将图像中有意义的特征部分提取出来，这是进一步进行图像识别、分析和理解的基础。虽然目前已经研究出不少边缘提取、区域分割的方法，但是还没有一种普遍适用于各种图像的有效方法。因此，对图像分割的研究还在不断深入中，是目前图像处理中研究的热点之一。

图像识别的最后一步是图像分类，图像分类属于模式识别的范畴，图像分类常采用经典的模式识别方法，近年来新发展起来的模糊识别和人工神经网络模式分类在图像识别中也越来越受到重视。

图像识别的研究具有重大意义，图像识别将是未来科技领域几大关键产业的核心技术之一。许多领域都将受益于图像识别技术的发展，最直接受益的是搜索引擎应用，引擎可以自动识别出每张图片中的物体并为其加注标签，用户搜索时的精度、自由度就会成倍的提升，这种进步会大大方便广告、电视、传媒行业及科研领域的相关工作。另一大将受益于图像识别技术的产业是无人驾驶交通工具，包括无人机和无人驾驶汽车。无人驾驶的核心技术是图像识别，如果电脑也能分辨出环境对象中的种类，就能像人类一样轻松应对复杂的情况：发现前方有只小狗在过马路，汽车要减速让行；可是如果一张报纸被风刮到了路中间就可以不用避让。图像识别的研究会对无人驾驶技术的发展带来巨大推动。未来图像识别技术还可以与虚拟现实系统相结合，用户带着类似HoloLens这样的眼镜观察四周，眼睛可以将自动视野内的物体一一分类，并自动根据使用者与周围环境的互动来判断其意图，真正能实现人工智能，让我们的生活更加便利。

微软、谷歌、Facebook、亚马逊、百度、腾讯等巨头都在大量倾注大量资源推动这项功能的进步。随着时间的推移我们会发现图像识别技术给我们生活带来的更多便利。



2、国内外研究现状和发展水平

图像识别是立体视觉、运动分析、数据融合等实用技术的基础，已经广泛应用在各个领域，如：遥感图像识别领域、通讯领域、军事、公安刑侦领域、生物医学图像识别领域、机器视觉领域等。在不久的将来，图像技术将经历一个飞跃发展的成熟阶段。图像技术的基础性研究，特别是结合人工智能与视觉处理的新算法，从更高的水平提取图像信息的内涵是一个艰难而重要的任务，国内外针对图像识别这一问题进行了广泛而深入的研究。

从百度、谷歌的无人车技术，Facebook的人脸识别技术到亚马逊云、谷歌云提供了图像识别的API以供用户调用。国内外的图像识别技术正在走向成熟。在现在的图像识别技术中与深度学习的结合成为一大研究热点。

自从Krizhevsky等人在ImageNet上训练一个8层的深度模型并在ImageNet竞赛上取得非常好的效果之后，卷积神经网络(CNN)在图像分类与识别领域受到了广泛的关注，取得了巨大的成功。之后，在很多图像识别应用的场景中，卷积神经网络也都取得了很大的性能改进。卷积神经网络能够逐层学习图像的特征，其中底层是具有普遍性(general)的特征，如图像的边缘、角点、纹理等；高层特征是低层特征的组合，是针对特定任务的有针对性(specific)的特征。逐层特征学习模拟了人脑分层处理信息机制，能够直接从原始像素得到图像特征。将卷积神经网络用于图像识别与分类，可以归纳为3种途径：1)直接在分类的数据集上训练一个深层的网络。随着CNN的深度和宽度增加，CNN的分类性能有着明显的提升。Simonyan等人提出了一个19层的CNN模型，该模型在原来的基础上通过增加卷积层来增加该模型的深度。Szegedy等人基于Hebbian原理和多尺度的启发提出了一个22层的深度学习模型GoogLeNet，它是由多个Inception Model堆叠而成。针对不同的分类任务，如场景分类和物体分类等，例如Zhou等在Place上训练的深度模型，对于场景分类有非常好的效果。

在图像特征提取方面，在训练好的网络上直接提取特征训练好的CNN模型可以用来直接用来当特征提取器，提取的特征可以用作其它的后续操作。Donahue等人利用Krizhevsky提出的模型将CNN的全连接层的特征将SVM分类器结合，在多个数据集上取得了很好的效果。相比之下，Liu等人采用跨卷积池化层技术将卷积层的特征作为通用的特征在MIT-67数据库上取得了更好的分类效果。Gong等人在多尺度下基于图像块提取CNN特征，然后通过主成分分析(principal component analysis, PCA)降维以及局部聚合的描述子向量(vector of locally aggregated descriptors, VLAD)编码等形成图像特征，相比于直接从整幅图片上提取CNN特征，该方法提取的特征具有几何不变性。

此外，在目标数据集上对现有的深度模型进行“精细化”调整(fine-tuning)，在特定数据集上训练好的模型有很强的泛化性能，但是fine-tuning能够进一步提升分类性能，在目标数据集上重新调整网络参数，使深度模型能够捕获针对目标任务更具有区分性的特征。表1给出了基于CNN的分类方法在不同的数据集上最好的分类准确率，表2给出了2014年ImageNet大规模视觉识别挑战(ILSVRC2014)的排名前7的结果，这些团队均是采用深度学习模型得到测试结果。







3、算法原理 技术路线的分析和比较

图像识别的常用方法有：贝叶斯分类法、模版匹配法、核方法、集成学习法、神经网络法等等。

(1)贝叶斯分类法，通过提取图像的代表特征并计算后验概率来对图像进行分类其基本思想是基于概率和决策代价，主要依据贝叶斯公式，假设要分类的问题可以用概率的形式来描述而且所有有关的概率都是已知的。其缺点是，有些时候，图像的代表特征并不能很好的被提取出来，或者提取出来的特征不能很好的用于分类。

(2)模版匹配法，将样本与模版比较，判断是否匹配。如果要检验某个目标，需要对其形状有一定的先验知识，来构造合适的模版，其缺点是，模版与未知样本匹配情况的好坏，将取决于模版上各个单元与样本的各个单元是否能够较好的匹配。

(3)核方法，是基于核函数的方法，典型的如支持向量机，将原始数据转换到高维空间，利用多个超平面将数据划分为多个类。

(4)集成学习方法，是用一系列学习器进行学习，并通过某种准则把各个学习的结果进行整合，从而获得比单一学习器更好的学习效果的一种方法，如bagging算法、Adaboost算法等。

本文就图像识别与深度学习神经网络相结合的的技术原理进行分析，以基于卷积神经网络的图像识别为例介绍了相关算法及技术。

神经网络是一个有向无环的网络结构，由许多个感知器分层互联而成；包括输入层，隐含层和输出层，每一层都含有多个神经元，不同层上的神经元存在着信息的传递。需要注意的是，神经元和神经元之间的连接并不是简单的加权，而是首先需要加入偏置，然后进行加权，最后还要通过一个激励函数进行映射，其原理如下图所示。



图1 sigmoid神经元

图中是从上一层网络神经元的输出信号，令表示从上神经元j到该层神经元i的权重，是偏置(bias)。将输入信号表示为X，将权值表示为W，那么，神经元i的输出与输入的关系可以表示为：





在众多的神经网络中，反向传播算法是性能最好且应用最为广泛的一种。其主思想是：导入训练样本，计算期望值和实际值的误差，然后通过不断的调整权重，减小两者误差，直到误差小到规定值为止。BP算法的具体步骤如下：

1)数据预处理，预处理的方法很多，比如说去噪、归一化等，普通的神经网络都要用到归一化，即将数据等比例的映射到[0,1]或者[-1,1]区间内，归一化处理可将大范围的数据映射到小范围区间，防止网络收敛慢，训练时间长；也可以提高算法精确度，减小误差；另外一个需要归一化的原因是：神经网络的激活函数如Sigmoid和Tanh函数只能处理以上两个区间的数据，只有在这两个区间上曲线变化才会明显。一般的归一化方法都是线性方法。

2)设置网络初始值，传统神经网络中，权重和阈值是随机给出的，一般随机化的权重都是较小的参数，过大的权值容易导致局部收敛和过拟合。

3)根据给定的权值和阈值以及sigmoid函数，计算隐含层各神经元的输入和输出依此向前传递，计算每一层的输出值，这个输出值是网络计算出来的值。

4)计算网络输出和期望值的差值，依次从前往后调整各个层次的权重，一般使用逻辑回归调节每个神经元的权值。

5)重复迭代，直到全局误差满足要求。

卷积神经网络的最大优势在于通过感受野和共享权重减少网络的参数，即参数减少和权值共享。图2描述了卷积神经网络的参数减少和权值共享：



图2 卷积神经网络参数减少和权值共享

在BP算法中，卷积神经网络反向传播算法基于梯度下降，迭代分为两个步骤：即向前传播产生输出结果和计算误差并通过反向传播调整权值。对于样本n，误差为：



其中C表示样本类别数，表示第n个样本的第k维对应的目标值(也就是目标分类)，表示第n个样本对应输出的第k维。在全连接网络中，网络的结构可以描述为：



其中激活函数f一般选用sigmoid函数。

接着要求误差对网络参数的偏导数，即用误差对偏置和权重求导。



由于，那么可以推出隐含层的灵敏度：



而输出层的灵敏度直接由本层直接决定，可以表示为：



由于隐含层并不存在能够直接使用的误差函数，那么反向传播算法通过上面的式子，将误差通过网络逐层向前传播，隐藏层的权值刻画了隐藏层对输出层的误差的贡献程度。最终，更新神经元权重的规则是用该神经元的输入乘以神经元的三角阵，即输入向量与误差信号向量的外积：







4、应用场景和应用水平的分析和比较

图像识别技术可以在多个场景中，下面简单介绍几个场景应用。

(1)视觉问答。视觉问答是近期受研究者关注的一个新方向。该技术将自然语言理解与视觉内容描述相结合，可以根据当前图像内容与用户问题产生出相应的回答针对当前的视觉问答主要有推理和端到端的深度学习这两种方法。

推理方法实现对真实世界的场景问答：该方法使用带有深度信息的数据集NVU-Depth V2dataset，对于场景使用语义分割算法构建世界并收集关于物体的识别信息，例如物体类别、3D位置和颜色；然后利用对于一个场景的多种world解释，这里的world解释是由语义分割产生；最后通过概率模型来得到最大后验概率的答案。图3给出了图像问答的CNN模型。



图3 提出图像问答的CNN模型

目前针对视觉问答的工作还不多，但是已经可以看到深度学习在这个领域中已经有了比较好的表现这主要得益于目前深度学习在视觉表示和自然语言理解等领域都有了长足的发展。

(2)面向移动终端的视觉识别技术。近些年来移动设备越来越普及，这些设备大多装配有摄像头和图形芯片，此外还有GPS和无线联网等功能，这些都促使移动端的视觉识别应用越来越多，常见的包括地标建筑物识别、商品识别、食品识别、艺术品识别等，上线的APP如Goggles等。

由于面向移动端，一些方法关注移动设备资源的合理利用，如提高传输速度、减 小内存开销等。Tsai等人提取低码率的CHoG特征，并利用了位置直方图编码对特征描述子的位置进行压缩，最后用几何验证的方法对检索结果进行重排序。He等人将图像的局部特征编码到位数较少的哈希而非对视觉单词(从而将图像表 码，VM)进行量化，表示成词袋型哈希码，然后采用边界特征对检索结果进行重排序。近年来，由于深度学习很强的特征学习能力已应用到各种移动视觉任务中。例如Teradeep公司已经针对移动和嵌入式设备开发了一套基于深度学习的算法实现移动端的场景理解、物体检测和识别等。百度等搜索公司也将深度学习技术比如DNN等应用到基于移动端的人脸识别、鞋识别和检索视觉任务中。

(3)面向机器人的图像识别技术。视觉识别技术在机器人领域也扮演着举足轻重的角色，作为机器人感知外界环境的一个重要的输出渠道，其对于机器人理解周围场景和辅助完成特定任务具有至关重要的作用。目前图像识别技术在机器人领域的应用主要有环境理解、自学物体识别和智能交互、导航与避障等。

图像识别在机器人视觉感知上主要是基于2D图像的识别，2D图像识别中主要是对获取到的图像进行物体检测和整体场景识别。基于2D图像的识别可以直接对图像进行特征提取或者对图像进行区域特征 提取然后使用模型进行标签预测。Rouanet等人的方法在交互过程中利用用户指定区域，从而缩小图像区域，然后对该区域提取特征并进行物体识别，这里为了进行增量式学习，采用了产生式模型进行物体识别。Wang等人给出了一种实例级物体识别方法，利用图像检索方式匹配输入图像与数据库中的图像，再经过空间一致性验证和投票机制实现 物体的识别，这种方法识别精度比较高，但是缺点是对于识别的物体不具有很好的泛化能力。

图像识别技术是机器人感知外界信息的重要渠道，因此未来在交互过程中利用视觉识别技术以增强机器人理解能力和提升与用户交互体验也具有很重要的研究价值，是一个具有挑战性的方向。例如利用图像识别技术同时识别人脸和物体， 可以帮助关联理解用户意图和兴趣爱好。目前受到大家广泛研究关注的图像描述和问答技术也会很快和机器人的视觉交互应用相结合，产生新的研究内容和应用场景，从而进一步促进视觉识别技术的发展和进步。



5、其它研究和应用情况

由于相关理论和技术的长足发展，在过去20年中，图像识别和智能交互技术发生了日新月异的变化。从小数据到大数据，从手工设计特征到以深度学习为代表的视觉特征学习，从简单内容到自然场景，从简单模型到复杂模型，从单一输出到复杂输出，从视觉识别到视觉理解、进一步到视觉描述和问答，视觉识别和智能交互技术已经逐渐从实验室走向现实的应用场景，相关方法尤其在深度学习方法、视觉和自然语言处理等技术深度结合的方面发展速度快，技术更新多。视觉交互的主要形式从普通设备逐渐迁移到智能终端和机器人，视觉信息处理能力越来越强，人机交互的体验也越来越真实。

通过以上分析和讨论，视觉识别和智能交互技术呈现出4个发展趋势：(1)深度学习方法由于其突出的泛化能力和视觉特征捕捉能力，将被应用在更深 层次、多角度的视觉识别和理解的各项技术当中；(2)图像识别和理解将与语言和认知技术进行更深入全面的结合，使得更加高级的视觉理解和描述性语义 输出取代简单的物体、场景识别而成为下一个10年的研究热点；(3)视觉识别和理解将会在具体的应用中进行更深层次的融合和适配，如特定内容的图像和视频识别等；(4)随着视觉描述和视觉问答的兴起，智能终端和机器人的视觉能力将在人机智能交互中起到越来越重要的作用，并将逐渐从较为局限的人机对话模式，进化为基于多通道智能信息处理的自然交互。

综上所述，图像识别结合深度学习有望在未来越多越多的领域中造福人类，会更加深入地为人类的生产、生活、消费和娱乐等提供智能化、个性化和全面化的服务。