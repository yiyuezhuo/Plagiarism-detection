人工智能2017综述报告









姓名：孙鑫

学号：117106021891













































语音助手的研究及产业应用情况

研究的主要内容和意义

研究的主要内容

语音助手要在智能电视上实现产品化，需要解决好硬件，智能电视操作系统，语音、语义识别，智能电视核心功能和应用和语音助手的整合，人机交互设计及实现。

语音识别是机器通过识别和理解过程把人类的语音信号转变为相应的文本或命令的技术。它的根本目标是研究出一种具有听觉功能和思维功能的系统，这种系统能直接接收人的语音，理解人的意图，并作出相应的反应【1】。从技术上看，属于多维模式识别和智能接口的范畴。语音识别技术是一项集声学、语音学、计算机、信息处理、人工智能等于一身的综合技术，可广泛应用在信息处理、通信与电子系统、自动控制等领域【2】。

语音识别技术拥有重要的理论价值和广阔的应用前景，在近年来获得了人们的广泛重视并取得了巨大进展。在人工神经网络尤其是深度神经网络方面的研究使得语音识别的准确程度和运算速度获得了极大提高，也使语音识别技术从实验室走向商业系统，逐步影响和改善着人们的工作和生活。BP网络表现出了人工神经网络最为核心的思想，现在在神经网络的实践使用中，基本上都是使用BP网络或其变化形式。

语音的识别流程大致上与人辨别及认知话语的流程是相同的。目前，语音识别技术己经接近成熟，其基本结构和流程也己经固定。一个科学合理的语音识别系统需要含有下面三个模块【3】：

语音特征提取模块:从音频信号中检测语音的前后端点并得出语音特征矢量序列，以便进行进一步的分析。

语音的学习训练和分类匹配模块:语音的学习模型是语音识别系统的基础，具有最重要的地位。一个学习模型一般由为每种词汇或语句生成的、己知的特征矢量序列通过学习建立的发音模板所组成。在识别时比较与匹配未知语音信号的特征序列和建立好的学习模型，根据与学习模型的相似度从而计算出未知语音的特征序列所属的种类。学习模型的设计随着语言发音特点的变化而变化，不同的语言形式会提取不同的语音特征，会大大的影响学习样本量的多寡、分类匹配的识别率，以及学习模型的适用性等方面。

语义理解模块:指计算机对识别结果语法、语义的分析。先要理解识别结果的意义，然后做出适当的反应。语义理解的实现一般依靠语言模型的建立。

研究意义

语音识别的技术成果主要应用在以下两个方面。

第一种应用是方便人与机器的交流。因为对许多普通人来说，不能熟练地使用键盘、鼠标与计算机或其他智能设备进行输入，人机交流的效率较低，影响到智能设备的进一步普及。使用语音识别技术，能够改变人与计算机的交互方式，人们只需要说几句简单的指令，就可以操作程序甚至操作系统。这种使计算机懂得人类语言的结果是使人们的双手解放出来，能够更好地操作和应用计算机和处理其它事务。智能手机是现今最为广泛使用的通信设备，通过在手机上嵌入语音识别系统，可以实现按人们的语音指令拨打电话、接通电话、语音处理电子邮件、搜索互联网信息等。或者能打开手机上的应用以及发展通过声纹来识别确认使用者身份的安全系统。目前这个方面取得了巨大进展，绝大部分的功能都己经实现了商业化。

第二种主要应用是将语音作为高效的输入端和灵活的输出端。在识别率达到一定水平的基础上，可以将语音作为一种文档的输入手段，普通人口述一篇文章的速度要比键盘输入的速度快2至4倍。装有语音合成软件的电脑和手机还能够“朗读”文章，这种应用建立在软件能够正确理解每句话的含义之上，从而做出正确的停顿和语调。也可以通过语音合成制作具有鲜明发声特色的虚拟声音，用于电视广播或影片的配音等。

国内外研究现状和发展水平

国外发展和现状

语音识别的研究工作起始于20世纪50年代，当时贝尔实验室制做出了世界上第一个语音识别系统一一Audry，但它只能识别英文中孤立的0到9这几个单词。语音识别真正被科学家所重视开始研究，并获得了突破性发展则是在60年代至70年代之间。这主要是缘于电子信息技术的快速发展，高效的硬件处理能力和软件编写环境为语音识别技术的实现奠定了良好的基础，值得一提的是语音信号线性预测倒谱(LPC)技术和动态时间规整(DTW)技术的提出，使语音信号的特征提取变得更加方便与准确，还有效地解决了不同长短的话音的识别难点，同时还提出了矢量量化(VQ)和隐马尔可夫模型(HMM)理论【5】。这段时间的语音识别技术主要以模式识别为基础，实现了基于LPC和DTW技术的语音识别系统，但是它的局限性很大:只能对特定人和己指定的词汇列表中的孤立词组进行匹配。

上世纪80年代末，语音识别在技术上取得了实质性的进展:人们终于解决了大型词库的分类识别、非孤立词的连续识别和非特定人发音的声纹识别这三个问题，使得语音识别系统变得智能、人性化，但还只能存在于实验室当中。最有代

表性的是卡内基梅隆大学的研究，它第一次做出了集成上述三种特性且识别效果良好的语音识别系统—狮身人面像系统【6】。在这一时期，隐马尔可夫模型和人工神经网络的数学模型被工程化并成功运用于语音识别技术里【7】，语音识别的研究进一步深化，更多的科研人员投入到它们的研究中来，也促使统计学理论变成了语音识别重要的一部分。

    到了20世纪90年代初，很多走在科技前沿的大型企业如IBM、苹果、Google和微软都将语音识别技术的商业化研究放在了重要位置。在二十世纪末，深度神经网络的出现和应用使得语音识别的准确率得到了稳步的上升。比较有代表性的系统有:IBM公司推出的Via Voice, Microsoft的Whisper, Sun的VoiceTone等【8】。

进入二十一世纪，语音识别技术开始真正走进人们的生活和工作，谷歌、苹果和微软分别提供了基于各自操作系统的、面向消费者群体的语音识别软件Google Now,  Siri和Cortana。它们兼顾了语音识别和智能搜索的功能，以可以直接与人类对话的小助手的身份，随着智能终端的普及，深入到了生活的方方面面。

国内发展现状

我国的语音识别研究工作晚于国外一段时间开始，但近年来进展十分快速，科研力度也在逐渐提升，同样完成了从实验室走向商业化的道路。国家与1987年开始执行863计划并单独为语音识别技术研究专门立项，目前我国语音识别技术的研究水准大致上同步于国外，达到国际领先水平，并在多次语音评测大赛上获得第一名。同时在普通话语音识别和国内方言的识别方面还有自己的特色与长处。中科院、各大科学院和高等院校等科研机构都有科研人员正在进行语音识别技术的研究。

随着移动信息化的不断前进，智能移动终端获得了迅速发展。以手机为例，智机代替功能机的进度越来越快，己经逐渐成为人们生活、文娱和工作必不可少的重要伙伴。其中搭载Android移动平台的智能手机以其系统的开放性、硬件的适应性和应用的丰富性成为了最受消费者欢迎的智能系统。

现在国内同样推出了市场化智能语音软件的主要有讯飞和百度。相比于国外，除了在中文语音识别的准确率方面有提高外，还能够支持各地方言。其中科大讯飞是我国走在前列的智能语音技术支持商，在技术方面拥有很深的底蕴，并在许多项研究上拥有超越国外的成就，如自然语音合成、语音识别、口语测试、自然语言分析等。

技术应用现状

在技术的不断追逐中，人们看到智能语音助手展现的巨大价值。虽然苹果的Siri自面世以来就成为了智能语音助手的代言人，但更多的公司希望用新的人工智能技术来超越现有的智能语音助手所覆盖的领域。Siri可以支持自然语言输入，并且可以调用系统自带的天气预报、口程安排、搜索资料等应用，还能够不断学习新的声音和语调，提供对话式的应答。Siri可以令iPhone及iPad变身为一台智能化机器人，利用Siri用户可以通过手机读短信、介绍餐厅、询问天气、语音设置闹钟等。2014年，微软官方发布了Cortana(小娜)这个类似Siri的个人语音助理平台。微软的小娜不仅可直接与微软搜索引擎必应相连，还能真正的充当个人助理。这意味着，它可以为主人做很多事情，比如安排会议、订购机票、设置闹铃，甚至能够讲笑话。从2015年起，国内也陆续出现了灵犀语音助手、百度语音助手、出门问问、欧拉蜜等多种应用。比如灵犀是山中国移动和科大讯吃联合推出的智能语音助手，既能为您语音打电话、发短信、查天气、设置提醒，又能帮你查话费、查流量、买彩票、订购彩铃，还可以陪你语音聊天。如今，越来越多的公司希望将将智能语音助手背后的自然语言解析技术运用到包括电子商务、娱乐行业等领域，使各个领域的客户能够创建自己的语音助手。比如全球最大的语音识别公司Nuance针对企业市场也不断推陈出新。Nuance的虚拟客服助理Nina集成了语音识别、语音合成以及自然语言理解技术。很多品牌都采用了山Nina平台提供技术支持的虚拟助理，其中包括达美乐比萨的Dom,荷兰国际集团的INGE、捷星航空的less以及美国联合服务汽车协会网站和澳大利亚税务局((aTO>新推出的虚拟助理。Nuance进入中国市场后在国内市场早已和HTC、华为、宏县和上汽等知名公司在移动终端设备和汽车领域建立了良好的合作关系。在中国企业客户自助服务方面，中国移动江苏省在10086客服号使用了由Nuance及华为合作实施的自然语言导航应用，浦发银行信用卡中心也同样部署Nuance自然语言理解(NLU)以及来电导航技术(小浦随心听)，为客户提供更加直观、拟人对话式的用户体验，成为了国内信用卡行业首家提供语音导航服务的银行。2017年，咖啡连锁巨头星巴克在公司的移动应用My Starbucks里推出了一项新的语音助手功能，方便用户通过语音点单和支付。借助该功能，用户便可修改自己的订单，就像在现实世界中与真的咖啡师交流一样。苹果也在开发受虚拟语音助手Siri支持的智能家居设备。据悉，苹果开发的智能家居设备能够通过语音控制屋内的各种电器、开关、灯光等。该设备的测试阶段还使用了面部识别技术。不同的是，Siri智能语音控制家居设备制胜的法宝分别是高质量的麦克风和语音处理技术。另有消息人士称，苹果还添加了脸部识别传感器。谷歌则将“谷歌助理”与家庭产品结合，推出了名为“谷歌家庭”的家用智能硬件。“谷歌家庭”犹如一只胖肚花瓶，是一款无线声控小型音响，可以连接电视、灯具和空调等家用电器。“谷歌家庭”这款家用智能硬件设备可通过与用户双向对话的形式开展持续“互动”，帮助用户完成一系列家庭口常活动。融合“机器学习”和在线搜索等技术，“谷歌家庭”可以对用户的语音指令作出反应，执行一系列家庭口常任务，比如播放音乐、关闭房间的照明、回答知识性问题、查询交通状况、帮用户修改预约等。用户通过自然说法的方式即可控制设备。目前谷歌正在Pixel中为Google Assistant添加全新功能，允许用户通过Google Assistant虚拟助理来控制智能家居设备，该功能被称为“Home Control"，而目前支持的智能家居厂商和产品包括贝尔金的Wemo，谷歌的Nest,吃利浦Hue以及三星的SmartThings系列。此次让Pixel拥有智能家居控制功能无疑带来许多便利:用户无需针对某个智能设备去单独下载操作该设备的APP。而且这种通用性也让用户无需购买Google自家的智能家居设备就能享受到语音控制的便利。如果家中的智能设备支持，用户能够向Pixel发出语音指令，就能调节屋内温度，控制照明，切换电视频道，播放音乐等。市场咨询公司Tractica发布的报告称，虽然目前最流行的还是智能手机消费者虚拟数字助手，但是虚拟助手技术已经开始进入其它设备，比如智能手表、健身追踪器、PC,智能家庭系统、汽车。在使用智能语音助手抢占AI入口市场的战斗中，美国电商巨头亚马逊公司推出的内置“亚历克萨”<Alexa)语音助理功能的“亚马逊回声”(Amazon Echo)智能音箱获得了巨大成功。该产品是贝索斯在2011年11月推出的，可以接受各种语音命令，使用的时候，只要说一声“Alexa"。Alexa的主要功能是让用户可以通过Echo的语音识别功能，操控任何一项具有联网功能的设备，比如电灯、电视、空调等等。得益于高效率的语音识别功能，Alexa可以帮助用户通过语音指令迅速驱动相关软件。据亚马逊的数据，Alexa在2014年最初发布时只有13个内嵌的技能，到了2016年11月，这项功能已经兼容6000款应用，包括连接Uber, Twitter等应用程序。到2017年3月，亚马逊宣布其Alexa智能语音助手平台的功能已经突破了一万种。亚马逊已经成为通过智能语音助手抢占A工入口的真正大赢家，它与LG,Dish Network、惠尔浦、华为、英特尔、福特的合作，不断扩大了Alexa的版图。

语音助手要在智能电视上实现产品化，需要解决好硬件，智能电视操作系统，语音、语义识别，智能电视核心功能和应用和语音助手的整合，人机交互设计及实现。

智能语音助手抢占AI市场，通过抢占A工入口市场，很多服务和商业行为都可以通过语音识别技术来实现智能化操作，特别是与物联网硬件的结合能为用户提供更全面的服务。

算法原理、技术路线的分析和比较

语音识别技术拥有重要的理论价值和广阔的应用前景，在近年来获得了人们的广泛重视并取得了巨大进展。在人工神经网络尤其是深度神经网络方面的研究使得语音识别的准确程度和运算速度获得了极大提高，也使语音识别技术从实验室走向商业系统，逐步影响和改善着人们的工作和生活。BP网络表现出了人工神经网络最为核心的思想，现在在神经网络的实践使用中，基本上都是使用BP网络或其变化形式。

数据的预处理是建立一个神经网络模型的前提与基础，因此语音信号的预处理在语音识别过程中具有十分重要的地位。其中，最重要的是语音信号的端点检测和特征提取。取得语音信号的特征后就可以建立神经网络，进行样本训练和匹配运算。

人工神经网络概述

人工神经网络(Artificial Neural Networks缩写为ANN)是一种数学计算模型，以仿生学的角度来看，它模拟了生物神经网络的组织结构和思维特点【4】.

人工神经网络在结构上将计算功能分布在多个处理单元中，在处理顺序上采用了并行处理机制，在知识信息存储方面采用了分布机制，知识不是存储在特定的存储单元内，而是分布在整个系统中。因此人工神经网络具有快速的信息处理能力、强大的容错能力和自我适应调节能力。神经网络以其独特的并行处理机制、自我训练能力、自我聚合和分类与联想和存储等特点，己广泛应用于非常多的领域。

由于各个方面之间的相互制约，模式识别的过程经常极其繁琐，为了针对这类非线性系统，人工神经网络应运而生，提供了非常大的支持。模式识别是人工神经网络最重要的特征之一，有助于解决实时处理随时间和空间变化的复杂动态信息等问题，近年来己经成为国内外语音识别技术科研领域的方向和热点。

神经网络的学习方式

广义上讲，根据神经网络功能的不同可以将其学习过程分为以下两种:有教师学习和无教师学习。按照相同的准则，无教师学习又可以分为无监督学习和强化学习两种方式。

   有教师学习也被称为监督学习。下图的方框图说明了这种学习方式的学习过程。理论上来说，教师可被认作是一个具有正确知识的判定模块，这些知识被表达为许多组输入输出对样本的集合，然而神经网络却完全不知道这些知识。现在假设给教师和神经网络提供相同的训练样例，教师可以根据自己己经掌握的知识进行判定而神经网络不能，但教师可以把自身得出的结果提供给神经网络作为期望的输出。实践应用中，期望输出事实上都作为神经网络能够给出的最优答案，可以定义神经网络的期望输出和实际输出的差为误差信号。一次学习过程中可以朝着减小误差信号的方向来调整隐藏层的各项参数，经过多次学习后，误差信号会越来越小，计算的终极目标就是要让神经网络学会教师的所有知识，从而代替教师进行匹配和识别。通过这种方法，神经网络就可以通过训练尽可能地掌握教师所掌握的全部知识，当训练达到一定程度的时候，就可以离开教师的监督，让神经网络完全独立地面对相应的环境。有教师学习系统是一个闭环反馈系统，其系统性能的测试手段可以采用训练样本的均方误差或平方和误差作为。

    无教师学习方式里，没有带有正确输出的测试样本提供给神经网络来训练。对于其中的强化学习来说，输入与输出之间的对应关系是通过周围环境的不断反馈而建立的，目标是使错误率(误差信号)越来越小。无教师学习系统建立在一个通过强化信号进行评价的基础上，如果系统的某个输出得到了环境反馈的积极响应，即正向的刺激信息，那么神经网络执行产生这个输出的配置的可能性就会增强，反之则会减弱。设计该系统的目的是为了适应期望输出结果未知情况下的学习，即意味着神经网络在每个离散状态都发现最优策略以保证得到的强化信号最大。

    在无监督或自组织学习系统中，不仅没有可参考的先验知识或者反馈来观测或修正训练的过程与结果，而且在指导神经网络时不指定匹配的种类和方式，而是在得到正确结果时像强化学习方式那样给予激励，这种无监督学习类型叫做分类。相对的，另一种无监督学习类型称为聚合，系统的目的是发现训练样本中的相近之处，从而自动创造新的类别。竞争性学习规则是网络里面以某种算法来选择“取得优势”的神经元，从而完成无监督学习。简单的情况中，系统可以采用在计算层中添加竞争层的设计方案，竞争层由相互竞争的神经元组成，每个神经元都争取获得“胜利”的机会，以便得到最佳的输出。神经网络最直白的竞争规则就是采用“胜者为王”的策略，竞争层的每个节点都有输出，其中输出最正确的神经元即为获胜的神经元，唯有“胜者”才淘汰才能够修正它的权值或其他参数，其余节点均被淘汰。

3.2  神经网络的的结构分类

    根据神经网络中神经元的构造方式，可以将神经网络分为单层前馈网络、多层前馈网络和递归网络三种形式【9】。

    在分层网络中，神经元的基本构建形式是层。前馈神经网络可能只包含源节点和计算节点，它们分别构成输入层和输出层，输入层和输出层是一个单一的线性关系，这样一来，此网络就属于无隐藏层的严格前馈网络【10】。这种结构之所以叫做单层前馈网络是因为负责计算的只有一层，也就是输出层，输入层并不参与运算。

    前馈神经网络也可能会有一层或多层的隐藏层。隐藏层是指该层不能直接地被观察到，无论从网络的输入端或者输出端，隐藏层包含的计算节点被称为隐藏神经元隐藏层的功能是连接外部输入层神经元和网络输出层神经元，并通过自身的权值变化和计算来改变整个网络的输出。通过增加隐藏层，网络可以根据其输入计算出更高阶的统计特征。输入向量由源节点构成的输入层进入，经运算后的输出结果输入到第二层也就是第一隐藏层，第二层的输出信号再输入到第三层，以此类推，就构成了整个计算单元。每一层的输出构成下一层的输入，而且只有相邻的两层之间才能进行数据交换，最后一层隐藏层的输出信号传递给输出层的节点并完成计算网络最终的输出结果。假设一个前馈网络具有m个源节点，第一隐藏层有k1个神经节点，次级隐藏层有k:个神经节点，输出层有n个神经节点，就可以记为m-ki-ka-n网络。

递归网络有一个或不止一个的自身反馈结构，这是它与前馈网络最主要的差别。反馈环的存在深刻影响着网络的学习能力和识别能力，可以用来实现联想记忆和求解优化等问题。

3.3  BP神经网络的简述和分析

    BP (Back Propagation)神经网络是一种对非线性可微分函数按误差逆传播算法训练的多层前馈网络，系统地解决了多层神经网络中隐层连接权的学习问题。BP网络表现出了人工神经网络最为核心的思想，现在在神经网络的实践使用中，基本上都是使用BP网络或其变化形式。

    BP神经网络是一种由输入层、隐藏层(一层或多层)和输出层组成的多层神经网络。当一个训练样本进入到BP神经网络后，所有的神经节点会生成相应的权值，随之以减少实际输出与期望输出间的误差信号为目标，从输出层开始，经过各中间层逐步修改所有神经元的连接权值，直到返回输入层。来回重复这两个步骤，一直到神经网络的误差信号小于期望的阈值，从而结束训练的过程。

3.4  语音信号的端点检测

精准地找到语音开始和结束的时刻是提取出真正需要处理的语音信号的基础，这种做法不仅为在录音时正确地判断开始和结束的时刻提供了依据，而且也减少了数据量，排除了干扰，提升了识别效果。端点检测作为语音分割的重要特征，目前比较流行的是双门限检测算法，同时使用短时过零率和短时平均能量来分别检测语音信号，两种方法联手从而获得了精确的端点检测算法。

一段语音信号一般可分为无声段、清音段和浊音段，它们的短时平均能量依次增高。通过计算短时平均能量可以大致区分这三种语音阶段。一般来说，需要将先语音信号分隔成小段(帧)，然后分别算出每段的短时平均能量，再通过设置门限来判定该帧属于哪种阶段。但是仅仅使用上述方法是不可靠的值的选取不当或声音信号较弱时，基于能量的算法几乎无法给出正确的结果，而同时采用短时过零率算法能够解决这些问题。过零率指的是一帧信号中波形穿越零电平的次数，清音段信号的短时过零率高，而浊音段的短时过零率较低，利用这一点可以进一步区分当前帧信号所属的阶段。

双门限端点检测算法的基本流程是:先要为短时平均能量和短时过零率分别设置一个较弱强度下信号就可通过的低门限和一个达到一定强度后信号才能通过的高门限。若是两个指标有一个超过了低门限就应该标记起始位置，并持续检测后续帧信号的平均能量和过零率。若是两个待测指标的数值都比低门限要低，则可以判定有效的语音信号还没有开始，取消当前标记的起始点;而若是两个待钡(指标中其中有一个比高门限要高，就说明信号开始属于有效语音段。当前状态处于有效语音区间时继续计算后续帧信号，如果平均能量和过零率的数值都返回到低门限以下就标记结束位置，同样持续检测后续帧信号的能量或过零率。如果两个参数的数值有一个上升且处于高门限以上，则可以判定有效语音信号还没有结束，取消当前标记的结束点;但如果两个待钡(指标一直没有超过高门限，就表示语音信号结束了。

由于命令词可能不止一个字符，音频信号经历了开始、结束、再开始、再结束的过程。这就需要找出最先标记的起始点和最后标记的结束点，来确定该命令词的确切长度。双门限检测算法的流程图如图所示。



3.5 语音信号的特征提取

语音信号特征提取的实质就是把语音信号从模拟信号变为数字信号，用反映语音信号特点的一些特征参数来代表语音，将语音信号数字化以便用计算机来进行处理。特征参数是否能够区别语音信号和能否精确地取出特征参数将直接影响语音识别的精确程度。

语音信号的特征有多种度量标准，常用的有线性预测倒谱系数(LPCC)和梅尔频率倒谱系数(MFCC)。使用线性预测倒谱系数计算量小、易于实现，但抗噪能力较差，并且由于LPCC在所有频率上都是线性的，完全不同于人的听觉特征，因此在这里采用了梅尔频率倒谱系数来进行语音特征提取。

梅尔频谱倒谱系数(Mel Frequency Cepstrum Coefficient)是根据人耳的听觉模型提出的，近年来得到了广泛应用，能够更好地提高系统的识别性能。人的耳蜗实际上相当于一个滤波器组，在1 OOOHz以下与频率呈线性关系，1 OOOHz以上与频率呈对数关系，梅尔频率倒谱系数正是利用两者之间的相关方式，算出与频率相关的频谱特征。鉴于梅尔频率与频率之间并不是线性相关的，在频率超过一定范围后，MFCC的计算准确度反而降低。于是，实际情况下往往只计算低频率下的MFCC，舍弃中频和高频的MFCC。

梅尔频率与音频实际频率的具体关系如下:



MFCC参数的提取包括以下几个步骤:音频信号分帧、加窗后，经过快速傅里叶变换(FFT)将时域信号变成信号的功率谱;再用一组梅尔频标上线性分布的三角窗滤波器(通常取24个)对来信号的功率谱进行处理。大量实验表明，为了提升算法的识别性能，可以在语音特征中加入差分参数，在本程序中即使用了一阶和二阶差分参数，来更加精准地表示语音的频谱特性。

语音信号特征提取的流程图如图:



4  应用场景和应用水平的分析和比较

语音识别技术是现在科学研究的热点，语音助手也是当前移动客户端开发的热门方向。以人工神经网络为研究背景，对语音识别的过程进行了系统的研究。根据神经网络的理论基础和学习原理，主要研究了基于人工神经网络的孤立命令词语音识别并完成了相关算法。语音识别是机器通过识别和理解过程把人类的语音信号转变为相应的文本或命令的技术。它的根本目标是研究出一种具有听觉功能和思维功能的系统，这种系统能直接接收人的语音，理解人的意图，并作出相应的反应。从技术上看，属于多维模式识别和智能接口的范畴。语音识别技术是一项集声学、语音学、计算机、信息处理、人工智能等于一身的综合技术，可广泛应用在信息处理、通信与电子系统、自动控制等领域。

另外，结合语音识别算法设计和实现了一款基于Android开发平台的语音助手软件，完成了通过蓝牙耳机语音接打电话和语音收发短信的功能。

语音识别的技术成果主要应用在以下两个方面。第一种应用是方便人与机器的交流。因为对许多普通人来说，不能熟练地使用键盘、鼠标与计算机或其他智能设备进行输入，人机交流的效率较低，影响到智能设备的进一步普及。使用语音识别技术，能够改变人与计算机的交互方式，人们只需要说几句简单的指令，就可以操作程序甚至操作系统。这种使计算机懂得人类语言的结果是使人们的双手解放出来，能够更好地操作和应用计算机和处理其它事务。智能手机是现今最为广泛使用的通信设备，通过在手机上嵌入语音识别系统，可以实现按人们的语音指令拨打电话、接通电话、语音处理电子邮件、搜索互联网信息等。或者能打开手机上的应用以及发展通过声纹来识别确认使用者身份的安全系统。目前这个方面取得了巨大进展，绝大部分的功能都己经实现了商业化。

第二种主要应用是将语音作为高效的输入端和灵活的输出端。在识别率达到一定水平的基础上，可以将语音作为一种文档的输入手段，普通人口述一篇文章的速度要比键盘输入的速度快2至4倍。装有语音合成软件的电脑和手机还能够“朗读”文章，这种应用建立在软件能够正确理解每句话的含义之上，从而做出正确的停顿和语调。也可以通过语音合成制作具有鲜明发声特色的虚拟声音，用于电视广播或影片的配音等。

通过对语音音频的处理和对语音识别技术的研究，理论分析了音频信号的端点检测、特征提取、建立人工神经网络模型和匹配识别整个流程，并且给出了各个环节的具体实现方案。

语音助手的开发涉及Android蓝牙通讯，音频的录制与存储，联系人信息的读取和查询，客户端与服务器的交互，电话及短信的事件监听和操作等相关功能模块，先后经历了分析设计、软件开发和系统测试等阶段，最终实现只需操作蓝牙耳机就可完成全部功能的移动平台APP。

参考文献：

[1] 曾妮，费洪晓，姜振飞.基于HTK的特定词语音识别系统[[J].计算机系统应用，2011,3:157-160

[2] 王文慧.基于ARM的嵌入式语音识别系统研究[D].天津大学.2008

[3] 俞铁城.语音识别的发展现状[[J].通信市场，2005,5:36-37

[4] Richard Lippmann.Review of Neural NeW orks for Speech Recognition[J].Readings in Speech Recognition,1990:374-392

[5]   De  Mori,R.Planning,neural  networks  and  Markov  models  for  automaticspeech  recognition}J}.IEEE.Pattern Recognition.1988:395-402

[6] KF Lee,R Red街.Automatic Speech Recognition: The Development of the Sphinx Recognition

    System[M].Kluwer Academic Publishers Norwell, MA, USA

[7] S.Rends et a1.A comparative stu街of continuous speech recognition using neural neW orks and

    hidden Markov models[J]. ICASSP,1991

[8] 孟祥斌.低码率语音识别特征参数MFCC提取的模块设计[D].哈尔滨工业大学.2006

[9] Simon Havkin.Neural Networks and Learning MachinesfMl.Prentice Hall

[10]  Friedrich B K,Barmann F.A learning Algorithm for Multilayered Neural Networks Based on Linear Square Problems}J}.Neural Networks,1993,4:127-132