智能搜索技术研究综述

























学院    计算机学院  

专业    计算机技术  

姓名       马娜     

学号   117106021945 









2017年12月1日





摘要

随着信息技术的迅速发展和Internet的广泛普及，信息搜索成为广大网络用户获取互联网信息的主要手段。在网络上信息量成几何级数的增长，人们将怎样在网络上搜索自己需要的信息。传统的搜索引擎技术在日益庞大的信息量面前逐渐显得力不从心。在这样的状况下，智能搜索引擎技术应运而生，也成为当前搜索引擎技术发展的主要方向。智能作为高级脑机界面的雏形或初级状态，是人工智能技术的重要方向，当前已成为学术界和产业界高度关注并持续研究的领域。文章针对智能搜索的发展现状，分析比较了传统搜索与智能搜索的异同，详细介绍了智能搜索中的几种信息检索模型以及链接分析算法，展望了智能搜索的发展趋势。

关键字：人工智能 智能搜索 检索模型 链接分析



























































1．引言

万维网WWW（World Wide Web）是一个巨大的、分布全球的信息服务中心，正在以飞快的速度扩展。1998年WWW上拥有约3.5亿个文档，每天增加约1百万的文档，不到9个月的时间文档总数就会翻一番。WEB上的文档和传统的文档比较，有很多新的特点，它们是分布的，异构的，无结构或者半结构的，这就对传统搜索技术提出了新的挑战。

传统搜索技术属于被动式搜索，依靠关键词索引技术，对关键词的相关网站进行机械呈现，让用户自己挑选需要的信息。经过二十几年的发展，尽管具有符合用户的使用习惯、市场运作成熟的特点，但由于其结构和服务理念原因，不能体现用户的个性化要求，面对参差不齐的用户，传统搜索只能尽可能的普遍化、全面化以适应不同搜索者的信息需求。同时还缺乏互动性，用户只能被动接受搜索引擎提供的信息，即用户只能从系统组织好的信息中选择自己所需要的信息，这样会导致用户搜索到的信息与用户本身所需信息存在一定的差距，相关性低。智能搜索技术则属于主动式搜索，结合智能分词技术、知识库系统、智能代理等方面的技术，除了提供传统的快速检索、相关度排序等功能，还能提供用户兴趣自动识别、内容语义理解、信息过滤和推送等功能，可以进行语音、图片、视频搜索，搜索结果更加人性化、更贴近用户需求，响应速度更快、搜索效率更高，注重提供知识和服务。智能搜索技术和人工智能技术相辅相成，相互促进。搜索引擎具备的天然数据优势，极大地促进了人工智能技术的发展；同时，人工智能算法的性能提升，又带动了智能搜索准确率和效率的大幅提升。

本文剩余部分安排如下，第2节介绍了智能搜索的国内外研究现状，第3节介绍了相关的信息检索模型，第4节分析比较了智能搜索中几种链接分析算法，第5节介绍了智能搜索的发展趋势，第6节作出总结。





































2．国内外研究现状

随着互联网技术的发展，现有的搜索技术已不能满足人们的查询需求，主要体现在：查询速度慢；对数以万计的查询结果缺乏准确的、有效的相关度评价，所以需要进一步进行理论上的研究和技术上创新、改进；查全率低等。目前，国内外这方面研究的主要成果有：

(1)通过对网页的评价探讨智能化搜索问题。美国斯坦福大学的Sergey Brin和Lawrence Page 1998年发表论文，利用现有的超文本结构，提出和构造了大规模搜索引擎的原型系统Google 和PageRank算法，它可以自动地、高效地收集和索引Web网页(管理和索引2.4亿页面)，能够根据用户查询寻找到更加令人满意的结果。IBM研究院的Jon Kleinberg研制开发了Clever原型系统，将Web上的网页用权威型和目录型两种概念去描述，采用HITS(Hyperlink Induced Topic Search)的相应算法计算每一网页的Authority值和Hub值，以改善检索质量。

 (2)通过用户访问行为的分布统计方法来研究智能化搜索引擎。由于WWW上网页质量参差不齐，其组织性和结构性较差，且检索的用户缺乏相关的技能和知识，有的学者就提出能不能利用用户的访问行为信息来提高检索的性能和效率，因为用户是搜索引擎的直接使用者和最终的评判者。北京大学的王建勇等人在中国科学上发表论文[3]，研究了在“天网”系统上统计分析大规模搜索引擎系统的用户行为特征。实验证明用户的查询内容与URL点击之间表现出局部性，其分布符合幂函数的特征，并具有良好的自相似性。同时还提出了LRU、LFU、FIFO三种Cache策略。

国外从事用户访问行为研究的学者也比较多，C.Holscher和G.Strube将用户划分为二类：专业人士、新手(Experienced Users and Casual Users)，并进行调查，不同知识背景的人对搜索引擎性能和效率的评价标准是不同的，也决定了他们的访问行为是有所偏好的[4]。根据这些不同类用户的访问行为考虑设计不同类型的搜索引擎。但是，这类研究存在的问题在于，对单个用户所关心的信息了解不够。

(3)通过对个性化搜索访问行为的研究探讨智能化搜索引擎。M.Perkowitz提出了PageGather算法[5]，利用Web 历史日志挖掘用户的存取模式，从一些用户访问过的候选页面中归纳出一些优化的页面访问序列，满足用户个性化服务的需要。R.Barrett和P.Maglio等人研制开发了WBI系统[6]，通过这些Agent在用户工作站上完成对用户最近访问的数据流的观测、记录，并对过去发生的访问数据流进行更新。这些Agent可以从记录的数据中获取用户的访问行为。国内对个性化的搜索引擎也已有一些研究，张卫丰等人提出了个性化代理系统的结构(PSA)[7]，韩立新等人利用用户的访问模式、类层次结构和多关键词构造个性化信息检索系统等等[8]。信息过滤机制也属于个性化检索的研究范畴[9]，信息过滤系统的主要目标是匹配信息空间和用户兴趣空间。现在的个性化检索的研究存在不足，表现在：1)不能综合考虑用户的浏览行为与用户检索页面的内容；2)对用户多方面兴趣的考虑仍不够；3)个性化检索的自动化程度不高，需要利用机器学习技术对用户提供大量的反馈信息进行训练；4)不能准确把握用户的信息需求且不能很好地适应用户需求的变化。

(4) Internet上分布式智能化信息获取方法的研究。研究人员引入分布式系统和Agent的概念，针对普遍存在的可扩展性、可靠性、可获得性和查询服务智能性关键技术展开研究，试图构造面向Internet的智能化分布式信息检索系统[10]。

(5)基于KDD方法的智能化信息获取方法的研究。近年来，KDD(Knowledge Discovery in Database)已成为一个十分活跃的领域，研究人员将KDD、DM与网上搜索引擎的研究结合起来，用以研制高质量、高效率的检索工具[11]。目前的研究成果还存在两点不足：1)主要表现在发现的规则的可用性还不理想(模式和规则中领域知识、信息不够)；2)算法对数据过于敏感而导致模式粒度过小而数量过大。对于搜索引擎，一般采用速度、查准率、查全率和失效率来评价其性能[12]。

在算法层面，智能搜索涉及到自然语言处理、机器学习、计算机视觉、人机交互、数据挖掘和信息检索等人工智能技术。其中涉及的关键技术有多个方面。自然语言处理：理解用户的搜索组合，甚至是准确理解用户的口语化表述，这是人工智能领域最核心的技术；多模交互：用户可以通过文本、图片、语音等方式进行人机交互；多轮交互：模仿人与人的多轮沟通方式，精准理解用户的需求；机器学习：通过与用户的沟通，越来越了解用户，为用户提供更强体验的服务。当前主流搜索引擎大都在算法层面融合了上述技术，如百度的智能搜索、谷歌的Rank-Brain、Facebook 的Deep Text、雅虎的CaffeOnSpark和微软的RankNet等。

全球搜索引擎市场竞争格局稳定。截至2017年5 月底，在全球搜索引擎市场份额比拼中，Google排名第一，份额为77.98%；微软必应搜索Bing 以7.81%的份额排名第二；百度以7.71%的市场份额排名第三[13]。而截至2017年6月底，我国搜索引擎用户规模达6.09亿，使用率为81.1%，用户规模较2016年底增加707万，增长率为1.2%；手机搜索用户数达5.93亿，使用率为81.9%，用户规模较2016年底增加1760万，增长率为3.1%[14]。在整体网民、手机网民中，搜索引擎均为第二大互联网应用，成为互联网服务形态的重要组成部分。





































3.信息检索模型

判断网页是否与用户查询相关，这依赖于搜索引擎所采用的检索模型。关于检索模型的研究，从信息检索学科建立之初就一直是研究重点，到目前为止，已经提出了多种各异的模型，如集理论模型(SetTheoretic Model)、代数模型(Algebraic Model)、概率模型(Probabilistic Model)和混合模型(Hybrid Model)。

3.1 集理论模型

布尔模型(Boolean Model)属于这种模型。布尔模型用文档的RSV(Retrieval Status Value)作为评估查询和文档相似性的方法。首先定义索引单词集，索引单词可以表示为，，…，，且可以描述如下：



这些索引单词可以和逻辑操作符AND、OR和NOT形成不同的条件查询;如果得到条件表达式的值为TRUE，该文档相对于此条查询的RSV值为1；如果所有文档相对于此条查询的RSV值都为1，则我们可以认为，这些文档与此用户的查询是相关的。布尔模型的优点是比较简单， 用户可以使用任意复杂的查询表达式。但是检索效率不好，也不能对检索的结果按从高向低的顺序进行排序，因为所有检索到与用户查询条件相关的文档具有相同的RSV值，且检索单词没有考虑权重的影响。现在一些商业系统的搜索引擎就是建造在这种模型的基础上。

3.2代数模型

向量空间模型(Vector Model)就属于一种代数模型。查询与文档的相似性可以通过下面公式求解。



在式(2)中，文档可以用n维的向量表示，其中每个分量表示某一Term在整篇文档中的权重。Q=(，，...，), 其中表示在Q中的权重。但向量空间模型假定Term向量是正交的，不考虑Term向量之间的依赖关系。

3.3概率模型

在概率模型中，需要考虑Term之间的依赖关系。它基于两个主要的参数Pr(rel)、Pr(nonrel)。Pr(rel)和Pr(nonrel)分别表示一个文档和用户查询的相关概率或不相关概率， 显然Pr(rel)=1-Pr(nonrel)。假设





R表示与用户查询相关的文档数，表示在R中出现Term t的文档数，N表示文档数，表示在N个文档中出现Term t的文档数。

考虑Term t出现的文档是不是与查询有关呢?(一般我们做相关的假设)，由上面所给的条件概率，根据贝叶斯定理，可以推导出Term t的权重：



如果>0，表明词Term t出现的文档与用户查询相关；如果<0，出现Term t的文档与用户查询无关；但上述条件概率Pr的值很难估计，可以对完全建立在经验中的判断提供一种理论上的指导。

3.4混合模型

混合模型又称为扩展的布尔模型（ExtendedBoolean Model）我们可以用下面来描述：



在式(6)中，d表示向量空间中的向量；，，…，表示向量d的分量；|d|表示向量d的模；且1≤p≤∞。当p=1这种情形和代数模型形式相同；当p=∞, 且不考虑索引词权重的影响，这种情形类似于严格的布尔模型；一般情况下，比较合适范围是2≤p≤5。





































4.链接分析算法

许多研究者发现，WWW上超链结构是个非常丰富和重要的资源，如果能够充分利用的话，可以极大的提高检索结果的质量。基于这种超链分析的思想，Sergey Brin和Lawrence Page在1998年提出了PageRank算法，同年J.Kleinberg提出了HITS算法，其它一些学者也相继提出了另外的链接分析算法，如SALSA、PHITS、Hilltop等算法。这些算法有的已经在实际的系统中实现和使用，并且取得了良好的效果。

4.1 PageRank算法

PageRank是Google创始人、斯坦福大学的博士研究生Sergey Brin和Lawrence Page在1998年构建早期搜索系统原型时提出的超链接分析算法（如图1），自从Google在商业上获得空前的成功后，该算法也成为其他搜索引擎和学术界十分关注的计算模型，目前很多重要的链接分析算法都是在PageRank算法的基础上衍生出来的[15]。



图1 Google提出的PageRank算法

	PageRank算法是基于两个前提。第一个前提，一个网页被多次引用，则它可能是很重要的；一个网页虽然没有被多次引用，但是被重要的网页引用，则它也可能是很重要的；一个网页的重要性被平均的传递到他所引用的网页，这种重要的网页称为权威（Authoritive）网页。第二个前提，假定用户一开始随机的访问网页集合中的一个网页，以后跟随网页的向外链接向前浏览网页，不回退浏览，浏览下一个网页的概率就是被浏览网页的PageRank值。PageRank算法描述如下：u是一个网页，F(u)是u指向的网页集合，B(u)是指向u的网页集合，N(u)是u指向外的链接数，显然N(u)=|F(u)|，c是一个用于规范化的因子（Google通常取0.85），则u的Rank值计算如下：



此为算法的形式化描述，也可以用矩阵来描述，设A为一个方阵，行和列对应网页集的网页。如果网页i有指向网页j的一个链接，则=1/，否则=0。设V是对应网页集的一个向量，有V=cAV，V为A的特征根c的特征向量。实际上，只需要求出最大特征根的特征向量，就是网页集对应的最终PageRank值，可用迭代方法的计算。

	Google是结合文本的方法来实现PageRank算法的，所以只返回包含查询项的网页，然后根据网页的Rank值对搜索到的结果进行排序，把Rank值最高的网页放置在最前面，但是如果最重要的网页不在结果网页集中，PageRank算法也就无能为力了，比如在Google中查询search engines，返回的结果网页中并没有出现。在此基础上，华盛顿大学计算机科学与工程系的Matthew Richardson和Pedro Dominggos提出了结合链接和内容信息的PageRank算法，去除了PageRank算法需要的第二个前提，增加考虑了用户从一个网页直接跳转到非直接相邻的但是内容相关的另外一个网页的情况。此外，斯坦福大学计算机科学系Taher Haveliwala提出了主题敏感（Topic-sensitive）PageRank算法，提高了结果的相关性和主题性。

4.2 HITS算法

HITS（Hypertext-Induced Topic Search）算法是由康奈尔大学的Jon Kleinberg于1998年提出的，属于IBM Almaden研究中心的名为“CLEVER”研究项目的一部分。

HITS算法利用Hub/Authority的方法，将查询q提交给传统的基于关键字匹配的搜索引擎，搜索引擎返回很多网页，从中取前n个网页作为根集（root set），用S表示，S满足以下三个条件：（1）S中网页数量相对较小；（2）S中网页大多数是与查询q相关的网页；（3）S中网页包含较多的权威网页。通过向S中加入被S引用的网页和引用S的网页将S扩展成一个更大的集合T。以T中的Hub网页为顶点集，以权威网页为顶点集，中网页到中的网页的超链接为边集E，形成一个二分有向图SG=(,,E)。对中的任一个顶点v，用h(v)表示网页v的Hub值，对中的顶点u，用a(u)表示网页的Authority值。开始时h(v)=a(u)=1,对u执行I操作修改它的a(u)，对v执行O操作修改它的h(v)，然后规范化a(u)、h(v)，如此不断的重复计算下面的操作I、O，直到a(u)、h(v)收敛。

I操作：               

O操作：               

每次迭代后需要对a(u)、h(v)进行规范处理：





HITS算法最后输出一组具有较大Hub值的网页和具有权威值的网页。

	尽管HITS算法目前为止也取得了很好的应用效果，但也存在一些问题。第一，在实际应用中，由S生成T的时间开销昂贵，需要下载和分析S中每个网页包含的所有链接，并且排除重复的链接，一般T比S大得多，由T生成有向图也很耗时，需要分别计算网页的A/H值，计算量远大于PageRank算法。第二，主机A上的文档可能指向主机B上的某个文档，这就增加了A中文档的Hub值和B中文档的Authority。第三，网页中的一些无关链接（比如商业广告）也会影响A/H值的计算。第四，HITS算法只计算特征向量，即T集合中的主社区，忽略了其他重要的社区。第五，HITS算法还存在主题漂移问题（topic drift），也就是紧密链接TKC（Tightly-Knit Community Effect）现象。第六，在进行主体查询时，HITS算法可能产生主体泛化问题，即扩展后引入了比原来主题更重要的新主题，这可能与原始查询无关。

	针对第二个问题，Monika R.Henzinger和Krishna Bharat提出了IMP算法，还引入了传统信息检索的内容分析技术来解决第四、第五个问题。IBM Almaden研究中心的CLEVER工程组提出了ARC（Automatic Resource Compilation）算法，对原始的HITS算法做了改进。Allan Borodin等人提出了Hub平均（Hub-Averaging-Kleinberg）算法，使仅指向权威值高的网页的Hub值比既指向权威值高又指向权威值低的网页的Hub值高，同时还提出了三种阈值控制算法：Hub阈值算法、Authority阈值算法、全阈值算法（前两者的结合）。

4.3 SALSA算法

PageRank算法是基于用户随机的向前浏览网页的直觉知识，HITS算法考虑的是Authority网页和Hub网页之间的加强关系。在实际应用中，用户大多数情况下向前浏览网页，但很多时候也会回退浏览网页，基于这种直觉，R.Lempel和S.Moran提出了SALSA（Stochastic Approach for Link-Strusture Analysis）算法，考虑了用户回退浏览网页的情况，保留了PageRank的随机漫游和HITS中把网页分为Authority和Hub的思想，取消了Authority和Hub之间的相互加强关系。

4.4 PHITS算法

HITS 算法在通过链接进行权值传递时，会将Hub或者Authority节点的权值全部传递给所有相连链接，但有人认为不同链接其传递权值的能力应该是不同的，基于这种思想，D.Cohn和H.Chang提出了计算Authority和Hub的统计算法PHITS（Probabilistic analogue of the HITS）。他们提出了一个概率模型，在这个模型里面一个潜在的因子或者主题z影响了文档d到文档c的一个链接，他们进一步假定，给定因子z，文档c的条件分布P(c|z)存在，并且给定文档d，因子z的条件分布P(z|d)也存在。





根据这些条件分布，提出了一个可能性函数（likelihood function）L，



其中M是对应的连结矩阵。然后，PHITS算法使用Dempster等提出的EM算法分配未知的条件概率使得L最大化，也就是最好的解释了网页之间的链接关系。算法要求因子z的数目事先给定。Allan Borodin指出，PHITS中使用的EM算法可能会收敛于局部的最大化，而不是真正的全局最大化。D.Cohn和T.Hofmann还提出了结合文档内容和超链接的概率模型。

4.5 Hilltop算法

	Hilltop算法是由Krishna Baharat在2000年提出来的，后授权给Google使用。它同样是计算链接关系，不过它更关注来自主题相关页面的链接权重。根据Hilltop算法，用户搜索关键词后，搜索引擎按传统算法挑出一系列初始相关页面，这些页面就是专家文件。Hilltop算法在这个页面集合中再次计算哪些网页有来自于集合中其他页面的链接，赋予比较高的LocalRank值。由于传统算法得到的页面集合已经具备了相关性，这些页面再提供链接给某一个特定页面，这些链接的权重自然应该很高。



上述这些算法有的处于研究阶段，有的已经在具体的系统实现了。这些算法大体可以分为四类:基于随机漫游模型的，比如PageRank、Repution算法；基于Hub和Authority相互加强模型的，如HITS及其变种；基于概率模型的，如SALSA、PHITS；基于贝叶斯模型的，如贝叶斯算法及其简化版本。所有的算法在实际应用中都结合传统的内容分析技术进行了优化。一些实际的系统实现了某些算法，并且获得了很好的效果，Google实现了PageRank算 法，IBM Almaden Research Center 的Clever Project实现了ARC算法，多伦多大学计算机系实现了一个原型系统TOPIC，来计算指定网页有声望的主题。AT&T香农实验室的Brian Amento在指出，用权威性来评价网页的质量和人类专家评价的结果是一致的，并且各种链接分析算法的结果在大多数的情况下差别很小。但是，Allan Borodin也指出没有一种算法是完美的，在某些查询下，结果可能很好，在另外的查询下，结果可能很差。所以应该根据不同查询的情况，选择不同的合适的算法。



























5.智能搜索的发展趋势

随着社会的日益信息化，智能搜索已成为一个新的研究、开发领域，它越来越引起人们的重视。智能搜索的发展主要表现在以下几个方面。

（1）提高信息查询结果的精度，提高检索的有效性

　　用户使用搜索引擎进行信息查询，并不关注返回结果的多少，而是看结果是否和自己的需求吻合。对于一个查询，传统的搜索引擎动辄返回几十万、几百万篇文档，用户不得不在结果中筛选。智能搜索引擎通过以下三种方法解决查询结果过多的现象：一是通过各种方法获得用户没有在查询语句中表达出来的真正用意，包括使用智能代理跟踪用户检索行为，分析用户模型；使用相关度反馈机制，使用户告诉搜索引擎哪些文档和自己的需求相关(及其相关程度)，通过多次交互逐步求精。二是用正文分类技术将结果分类，使用可视化技术显示分类结构，用户可以只浏览自己感兴趣的类别。三是进行站点类聚或相近内容类聚，减少信息返回的总量。

（2）提供基于智能搜索代理的信息过滤和个性化服务

　　智能搜索代理具有解决问题所需的丰富知识、策略和相关数据，能够进行相关的推理和智能计算，可以在用户没有给出十分明确的需求时推测出用户的意图、兴趣或爱好，并按最佳的方式完成任务，将用户感兴趣的、对用户有用的信息反馈给用户。智能搜索代理具有不断学习、适应信息和用户兴趣动态变化的能力，能自动过滤一些不合理或可能给用户带来危害的要求，并且根据环境适当地进行自我调节，提高问题的处理能力，从而提供个性化的服务。

（3）丰富知识资源库，改进知识搜索引擎技术

知识搜索是在搜索引擎发展进入智能化阶段的过程，是建立在明确的知识来源基础上，根据用户的身份与诉求，回馈恰当知识结果的搜索引擎。而知识资源库的丰富程度决定着知识检索程度的高低，它是实现智能搜索的基础和核心。目前知识搜索引擎的代表网站主要有：中国知网，它是目前最大的基于互联网出版的学术知识搜索引擎。通过丰富知识资源库和改进知识搜索引擎技术，更为强调知识的准确、标准，强调通过互动机制如评价、交流、修改、维护等进行搜索结果的自我学习，对信息进行接受、判断、提取、分析和概括之后形成自己的知识，保存后成为下一次分析、概括的依据和基础，从中检索出对用户最有价值的信息，以达到知识搜索的智能化。

（4）采用分布式体系结构提高系统规模和效能

智能搜索引擎的实现可以采用集中式体系结构和分布式体系结构。但是当系统规模到达一定程度(如网页数达到亿级)时，必然要采用某种分布式方法，以提高系统效能。分布式搜索引擎在架构和管理上采用“分布和集中相结合”的模式，具有集中式搜索引擎无法比拟的优势。通过充分利用服务器集群的各类资源，达到提高服务器性能、提升集群总体服务质量的目的。













6.结束语  

Internet 的信息量爆炸性递增，搜索引擎在用户和信息源之间架起了沟通的桥梁， 为人们迅速、方便地获取有效信息提供检索服务，起到信息导航的目的。当前的智能化搜索引擎能够实现信息服务的智能化、人性化、高效化，为用户检索互联网信息提供了方便，其发展是一个长期的过程。目前的搜索引擎主要提供基于文字内容的信息检索服务，而对于进一步提高检索结果的相关、个性化检索服务、支持多媒体检索、支持自然语言检索、 增强检索界面的友好程度等还有非常多的工作需要去做，搜索引擎要真正地实现智能化并不仅仅局限于概念上那么简单。但是我们要坚信，在科学技术的不断发展和推动下，一些高性能的满足不同需求的搜索引擎将会不断被开发出来。





























































参考文献

[1] 王冲鶄.智能搜索技术发展态势分析[J].现代电信科技,2017,47(3):75-78.

[2] 张骞.传统搜索引擎与智能搜索引擎比较研究[D].河南:郑州大学.2012.

[3] 王建勇,单松巍,雷鸣等.海量Web搜索引擎系统中的用户行为的分布特征及其启示[J].中国科学(E辑),2001,31(4):372～385.

[4] Holscher C,Strube G.Web search behavior of Internet experts and newbies [J].Computer Networks,2000,(33):337～346.

[5] Perkowitz M,Etzion O.Towards adaptive Web sites:conceptual frame work and case study [J].Computer Networks,1999,(31):1245～1258.

[6] Barrett R,Maglio P,Kellem D.How to personalize the Web[A].Proc.ACM CHI’97 [C].Atlanta,USA:1997.

[7] 张卫丰,徐宝文.利用Agent个性化搜索结果[J].小型计算机,2001,(6):724～727.

[8] 韩立新,陈贵海,谢立.一个面向Internet的个性化信息检索系统模型[J].电子学报,2002,30(2):240～244.

[9] 田范江,李丛蓉,王鼎兴.进化式信息过滤方法研究[J].软件学报,2000,11(3):328～ 333.

[10] 韩立新,陆桑璐,谢立.一个面向Internet的分布式信息检索系统模型[J].电子学报, 2002,30(8):1130～1133.

[11] Fayyad M,Piatetsky G,Smyth P.Advance in knowledge discovery and data mining [M].AAAI Press,2002.

[12] 韩家炜.范明.数据挖掘概念与技术[M].北京:机械工业出版社,2001.

[13] NetMarketShare. MarketShareReports[R],2017.https://www. netmarketshare.com.

[14] 中国互联网络信息中心.第40次中国互联网络发展状况统计报告[R],2017.

[15] 张俊林.这就是搜索引擎[M].北京：电子工业出版社,2011.