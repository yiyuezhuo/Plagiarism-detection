人工智能综述报告







人脸识别的研究及产业应用情况









学院：计算机科学与技术学院

课程：人工智能原理与方法

姓名：王胤多

学号：117106021933 









南京理工大学

2017年11月





目录

1研究的主要内容和意义	3

2国内外研究现状和发展水平	4

2.1国外发展水平	4

2.1.1 第一阶段（1964年-1990年）	4

2.1.2 第二阶段（1991年-1997年）	5

    2.1.3第三阶段（1998年-现在） 	7

2.2 国内发展水平及现状	11

3.算法原理、技术路线的分析和比较	13

3.1 人脸识别技术概述	13

 3.2人脸识别算法的框架	13

4.应用场景和应用水平的分析和比较	19

5 仍需挑战的方面 	21

6.结语	22



















1. 研究的主要内容和意义

人脸是人类情感表达和交流的最重要、最直接的载体。通过人脸可以推断出一个人的种族、地域，甚至身份、地位等信息；人们还能通过人脸丰富而复杂细小的变化，得到对方的个性和情绪状态。科学界从计算机图形学、图像处理、计算机视觉、人类学等多个学科对人脸进行研究。

   研究人脸识别在理论和技术上都有重要的意义：一是可以推进对人类视觉系统本身的认识；二是可以满足人工智能应用的需要。采用人脸识别技术，建立自动人脸识别系统，用计算机实现对人脸图像的自动识别有着广阔的应用领域和诱 人的应用前景。 

同时人脸识别作为一种生物体征识别与其它较成熟的识别方法（如指纹、虹膜、DAN检测等）相比有以下几个优点： 

①无侵犯性，人脸图像的获取不需要被检测人发生身体接触，可以在不惊动被检测人的情况下进行； 

②低成本、易安装，人脸识别系统只需要采用普通的摄像头、数码摄像机或手机上的嵌入式摄像头等被广泛使用的摄像设备即可，对用户来说也没有特别的安装要求； 

③无人工参与，整个人脸识别过程不需要用户或被检测人的主动参与，计算机可以根据用户预先的设置自动进行。由于具有以上优点，近几年来，人脸识别技术引起了越来越多科研人员的关注。







2. 国内外研究现状和发展水平

     1.国外发展水平

人脸识别的研究历史比较悠久。高尔顿(Galton)早在 1888 年和 1910 年就分别在《Nature》杂志发表了两篇关于利用人脸进行身份识别的文章，对人类自身的人脸识别能力进行了分析。但当时还不可能涉及到人脸的自动识别问题。最早的AFR1的研究论文见于 1965 年陈（Chan）和布莱索（Bledsoe）在Panoramic Research Inc.发表的技术报告，至今已有四十年的历史。近年来，人脸识别研究得到了诸多研究人员的青睐，涌现出了诸多技术方法。尤其是 1990 年以来，人脸识别更得到了长足的发展。几乎所有知名的理工科大学和主要IT产业公司都有研究组在从事相关研究。下面对三个阶段的研究进展情况作简单介绍。

第一阶段（1964年-1990年）

这一阶段人脸识别通常只是作为一个一般性的模式识别问题来研究，所采用的主要技术方案是基于人脸几何结构特征（Geometric feature based）的方法。这集中体现在人们对于剪影（Profile）的研究上，人们对面部剪影曲线的结构特征提取与分析方面进行了大量研究。人工神经网络也一度曾经被研究人员用于人脸识别问题中。较早从事 AFR 研究的研究人员除了布莱索（Bledsoe）外还有戈登斯泰因（Goldstein）、哈蒙（Harmon）以及金出武雄(Kanade Takeo)等。金出武雄于 1973 年在京都大学完成了第一篇 AFR 方面的博士论文，直到现在，作为卡内基-梅隆大学（CMU）机器人研究院的一名教授，仍然是人脸识别领域的活跃人物之一。他所在的研究组也是人脸识别领域的一支重要力量。总体而言，这一阶段是人脸识别研究的初级阶段，非常重要的成果不是很多，也基本没有获得实际应用。

第二阶段（1991年-1997年）
       这一阶段尽管时间相对短暂，但却是人脸识别研究的高潮期，可谓硕果累累：不但诞生了若干代表性的人脸识别算法，美国军方还组织了著名的 FERET 人脸识别算法测试，并出现了若干商业化运作的人脸识别系统，比如最为著名的 Visionics（现Identix）的 FaceIt 系统。美国麻省理工学院（MIT）媒体实验室的特克（Turk）和潘特（Pentland）提出的“特征脸”方法无疑是这一时期内最负盛名的人脸识别方法。其后的很多人脸识别技术都或多或少与特征脸有关系，现在特征脸已经与归一化的协相关量(Normalized Correlation)方法一道成为人脸识别的性能测试基准算法。这一时期的另一个重要工作是麻省理工学院人工智能实验室的布鲁内里（Brunelli）和波基奥（Poggio）于 1992 年左右做的一个对比实验，他们对比了基于结构特征的方法与基于模板匹配的方法的识别性能，并给出了一个比较确定的结论：模板匹配的方法优于基于特征的方法。这一导向性的结论与特征脸共同作用，基本中止了纯粹的基于结构特征的人脸识别方法研究，并在很大程度上促进了基于表观（Appearance-based）的线性子空间建模和基于统计模式识别技术的人脸识别方法的发展，使其逐渐成为主流的人脸识别技术。

     贝尔胡米尔（Belhumeur）等提出的Fisherface人脸识别方法是这一时期的另一重要成果。该方法首先采用主成分分析（Principal Component Analysis，PCA，亦即特征脸）对图像表观特征进行降维。在此基础上，采用线性判别分析（Linear Discriminant Analysis， LDA）的方法变换降维后的主成分以期获得“尽量大的类间散度和尽量小的类内散度”。该方法目前仍然是主流的人脸识别方法之一，产生了很多不同的变种，比如零空间法、子空间判别模型、增强判别模型、直接的 LDA 判别方法以及近期的一些基于核学习的改进策略。麻省理工学院的马哈丹（Moghaddam）则在特征脸的基础上，提出了基于双子空间进行贝叶斯概率估计的人脸识别方法。该方法通过“作差法”，人脸图像对的相似度计算问题转换为一个两类（类内差和类间差）分类问题，类内差和类间差数据都要首先通过主成分分析（PCA）技术进行降维，计算两个类别的类条件概率密度，最后通过贝叶斯决策（最大似然或者最大后验概率）的方法来进行人脸识别。

       人脸识别中的另一种重要方法——弹性图匹配技术(Elastic Graph Matching，EGM) 也是在这一阶段提出的。其基本思想是用一个属性图来描述人脸：属性图的顶点代表面部关键特征点，其属性为相应特征点处的多分辨率、多方向局部特征——Gabor变换12特征，称为Jet；边的属性则为不同特征点之间的几何关系。对任意输入人脸图像，弹性图匹配通过一种优化搜索策略来定位预先定义的若干面部关键特征点，同时提取它们的Jet特征，得到输入图像的属性图。最后通过计算其与已知人脸属性图的相似度来完成识别过程。该方法的优点是既保留了面部的全局结构特征，也对人脸的关键局部特征进行了建模。近来还出现了一些对该方法的扩展。 局部特征分析技术是由洛克菲勒大学(Rockefeller University)的艾提克（Atick）等人提出的。LFA在本质上是一种基于统计的低维对象描述方法，与只能提取全局特征而且不能保留局部拓扑结构的PCA 相比，LFA 在全局 PCA 描述的基础上提取的特征是局部的，并能够同时保留全局拓扑信息，从而具有更佳的描述和判别能力。LFA技术已商业化为著名的 FaceIt 系统，因此后期没有发表新的学术进展。由美国国防部反毒品技术发展计划办公室资助的 FERET 项目无疑是该阶段内的一个至关重要的事件。FERET 项目的目标是要开发能够为安全、情报和执法部门使用的 AFR 技术。该项目包括三部分内容：资助若干项人脸识别研究、创建 FERET 人脸图像数据库、组织 FERET人脸识别性能评测。该项目分别于 1994 年，1995年和 1996 年组织了 3 次人脸识别评测，几种最知名的人脸识别算法都参加了测试，极大地促进了这些算法的改进和实用化。该测试的另一个重要贡献是给出了人脸识别的进一步发展方向：光照、姿态等非理想采集条件下的人脸识别问题逐渐成为热点的研究方向。 柔性模型（Flexible Models）——包括主动形状模型（ASM）和主动表观模型（AAM）是这一时期内在人脸建模方面的一个重要贡献。ASM/AAM 将人脸描述为2D形状和纹理两个分离的部分，分别用统计的方法进行建模（PCA），然后再进一步通过PCA将二者融合起来对人脸进行统计建模。柔性模型具有良好的人脸合成能力，可以采用基于合成的图像分析技术来对人脸图像进行特征提取与建模。柔性模型目前已被广泛用于人脸特征对准（Face Alignment）和识别中，并出现了很多的改进模型。总体而言，这一阶段的人脸识别技术发展非常迅速，所提出的算法在较理想图像采集条件、对象配合、中小规模正面人脸数据库上达到了非常好的性能，也因此出现了若干知名的人脸识别商业公司。从技术方案上看，2D人脸图像线性子空间判别分析、统计表观模型、统计模式识别方法是这一阶段内的主流技术。 
       第三阶段（1998年-现在） 
         FERET96人脸识别算法评估表明：主流的人脸识别技术对光照、姿态等由于非理想采集条件或者对象不配合造成的变化鲁棒性比较差。因此，光照、姿态问题逐渐成为研究热点。与此同时，人脸识别的商业系统进一步发展。为此，美国军方在 FERET 测试的基础上分别于 2000 年和 2002年组织了两次商业系统评测。基奥盖蒂斯（Georghiades）等人提出的基于光照锥 (Illumination Cones) 模型的多姿态、多光照条件人脸识别方法是这一时期的重要成果之一，他们证明了一个重要结论：同一人脸在同一视角、不同光照条件下的所有图像在图像空间中形成一个凸锥——即光照锥。为了能够从少量未知光照条件的人脸图像中计算光照锥，他们还对传统的光度立体视觉方法进行了扩展，能够在朗博模型、凸表面和远点光源假设条件下，根据未知光照条件的7幅同一视点图像恢复物体的 3D 形状和表面点的表面反射系数（传统光度立体视觉能够根据给定的3幅已知光照条件的图像恢复物体表面的法向量方向），从而可以容易地合成该视角下任意光照条件的图像，完成光照锥的计算。识别则通过计算输入图像到每个光照锥的距离来完成。以支持向量机为代表的统计学习理论也在这一时期内被应用到了人脸识别与确认中来。支持向量机是一个两类分类器，而人脸识别则是一个多类问题。通常有三种策略解决这个问题，即：类内差/类间差法、一对多法（one-to-rest）和一对一法（one-to-one）。
      布兰兹（Blanz）和维特（Vetter）等提出的基于3D变形(3D Morphable Model)模型的多姿态、多光照条件人脸图像分析与识别方法是这一阶段内一项开创性的工作。该方法在本质上属于基于合成的分析技术，其主要贡献在于它在 3D形状和纹理统计变形模型（类似于 2D时候的 AAM）的基础上，同时还采用图形学模拟的方法对图像采集过程的透视投影和光照模型参数进行建模，从而可以使得人脸形状和纹理等人脸内部属性与摄像机配置、光照情况等外部参数完全分开，更加有利于人脸图像的分析与识别。Blanz 的实验表明，该方法在 CMU-PIE（多姿态、光照和表情）人脸库和FERET多姿态人脸库上都达到了相当高的识别率，证明了该方法的有效性。2001年的国际计算机视觉大会（ICCV）上，康柏研究院的研究员维奥拉（Viola）和琼斯（Jones）展示了他们的一个基于简单矩形特征和AdaBoost的实时人脸检测系统，在 CIF 格式上检测准正面人脸的速度达到了每秒15帧以上。该方法的主要贡献包括：1）用可以快速计算的简单矩形特征作为人脸图像特征；2）基于AdaBoost将大量弱分类器进行组合形成强分类器的学习方法；3）采用了级联（Cascade）技术提高检测速度。目前，基于这种人脸/非人脸学习的策略已经能够实现准实时的多姿态人脸检测与跟踪。这为后端的人脸识别提供了良好的基础。

       沙苏哈（Shashua）等于 2001 年提出了一种基于商图像13的人脸图像识别与绘制技术。该技术是一种基于特定对象类图像集合学习的绘制技术，能够根据训练集合中的少量不同光照的图像，合成任意输入人脸图像在各种光照条件下的合成图像。基于此，沙苏哈等还给出了对各种光照条件不变的人脸签名（Signature）图像的定义，可以用于光照不变的人脸识别，实验表明了其有效性。 巴斯里（Basri）和雅各布（Jacobs）则利用球面谐波（Spherical Harmonics）表示光照、用卷积过程描述朗博反射的方法解析地证明了一个重要的结论：由任意远点光源获得的所有朗博反射函数的集合形成一个线性子空间。这意味着一个凸的朗博表面物体在各种光照条件下的图像集合可以用一个低维的线性子空间来近似。这不仅与先前的光照统计建模方法的经验实验结果相吻合，更进一步从理论上促进了线性子空间对象识别方法的发展。而且，这使得用凸优化方法来强制光照函数非负成为可能，为光照问题的解决提供了重要思路。   

2007年以来，LFW数据库成为事实上的真实条件下的人脸识别问题的测试基准。LFW数据集包括来源于因特网的5，749人的13，233张人脸图像，其中有1680人有两张或以上的图像。LFW的标准测试协议包括6000对人脸的十折确认任务，每折包括300对正例和300对反例，采用十折平均精度作为性能评价指标。自从LFW发布以来，性能被不断刷新。2013年之前，主要技术路线为人造或基于学习的局部描述子+测度学习。2014年之后，主要技术路线为深度学习。  

2014年以来，深度学习+大数据（海量的有标注人脸数据）成为人脸识别领域的主流技术路线，其中两个重要的趋势为：1）网络变大变深（VGGFace16层，FaceNet22层）。2）数据量不断增大（DeepFace400万，FaceNet2亿），大数据成为提升人脸识别性能的关键。

2014年，Facebook发表于CVPR14的工作DeepFace将大数据（400万人脸数据）与深度卷积网络相结合，在LFW数据集上逼近了人类的识别精度。其中DeepFace还引入了一个Local Connected卷积结构，在每个空间位置学习单独的卷积核，缺点是会导致参数膨胀，这个结构后来并没有流行起来。

DeepID家族可以看作是DL时代人脸识别领域的一组代表性工作。最早的DeepID网络包括四个卷积层，采用softmax损失函数。DeepID2在DeepID网络的基础上，同时考虑了分类损失（identityloss) 和确认损失（verification loss），这两种损失在Caffe深度学习框架中分别可以采用softmaxwithloss层和contrastiveloss层来实现。DeepID2+网络则是在DeepID2的基础上，增加了每一层的辅助损失函数（类似Deep Supervised Network)。

       Google发表于CVPR2015的工作FaceNet采用了22层的深层卷积网络和海量的人脸数据（800万人的2亿张图像）以及常用于图像检索任务的Triplet Loss损失函数。值得一提的是，由于人脸类别数达到800万类，如果使用softmax loss，输出层节点将达到800万个，需要至少32GB显存（假设上一个隐层节点1024个，采用单精度浮点数），而Triplet Loss则不需要额外占用显存。FaceNet在LFW数据集上十折平均精度达到99.63%，这也是迄今为止正式发表的论文中的最好结果，几乎宣告了LFW上从2008年到2015年长达8年之久的性能竞赛的结束。

2.国内发展水平及现状

国内最早研究人脸识别的，当属于中科院计算所跟哈工大的一个联合面像实验室。计算所-哈工大人脸识别联合研究组从九十年代中期开始人脸识别的研究，并于2000年5月与成都银晨网讯（现上海银晨科技的前身）联合创立了国内首家专门从事面像识别核心技术研究与开发的实验室——ICT-ISVISION 面像识别联合实验室。该联合实验室从2001年起一直维持着20人左右规模的研究队伍。目前核心研究队伍包括2名教授，2名助理研究员，1名讲师和来自中国科学院计算技术研究所、哈尔滨工业大学计算机科学与技术学院以及中国科学院研究生院的十多名博士、硕士研究生。经过不懈努力，联合实验室近年来取得了一定的成果，主要包括：在预处理、人脸检测、人脸识别与确认等方面，提出了一系列新算法和改进算法。在光照可变、多姿态等条件下获得了优于其他系统的性能：1）性能明显优于FERET'97测试（美国DARPA组织的最近一次人脸识别比赛）的最好结果；2）与在 FRVT2002（美国NIST组织的最近一次人脸识别比赛）中取得第一的 FaceVACS 系统(Cognitec 公司)性能基本接近，在光照子库上性能明显超出对方；3）在中国首届生物特征识别评测竞赛 BVC2004 中，以绝对优势取得了第一名。在基础数据建设方面，收集整理了万人以上超过百万幅图像的人脸图像数据库 CAS-PEAL，公布了包含3万多幅人脸图像的大规模中国人脸图像数据库 CAS-PEAL-R1，已被国内外50余单位使用，在国际上率先提供了大规模共享中国人脸图像数据库。 在应用系统和成果转化方面，开发了会议代表身份认证/识别系统、银行智能视频监控系统、嫌疑人面像比对系统、面像识别考勤/门禁系统、出入口黑名单监控系统等19种产品；申请各类专利26项（8项已获授权），软件著作权11项。产品已成功应用于人民大会堂、天安门广场等重要场所及海南、云南省建行等多处。成果转化的产品在公安、金融等领域推广，取得了较好的经济和社会效益。这些研究成果结束了国内企业长期依赖国外技术、只能做二次开发商的历史，从总体上提高了我国相关技术的国际竞争力，也为我国生物特征识别及其相关产业发展起到了积极的推动作用。

其次是中科院生物识别研究所的李子青教授，以及下属的中科奥森公司。李子青教授，当年在微软亚洲研究院的时候，就从事人脸识别方面的研究工作。后来，在中科院组建了专门的人脸识别研究团队（当然是他跟他带领的一群博士硕士）。该研究团队，首先提出了基于近红外的人脸识别技术，并将该项人脸识别技术用于08年北京奥运会。同时，基于近红外的人脸识别技术，得到了国际上同行业专家的认同和一致肯定。

 接着，是清华大学的丁晓青教授。丁晓青教授在OCR(字符识别)领域，可谓国内第一人。不过，最近几年转行做人脸识别，也是非常有成就的。不说别的，就只从FRVT2006（美国国家标准研究所2006年全球人脸识别供应商系统性能测试）的测试结果来看，丁晓青教授的研究团队（自然也是丁教授跟她的博士、硕士）是唯一一个完成大规模3D人脸识别性能测试的参赛团队。



3. 算法原理、技术路线的分析和比较

   1.人脸识别技术概述

     近年来，随着计算机技术的迅速发展，人脸自动识别技术得到广泛研究与开发，人脸识别成为近30年里模式识别和图像处理中最热门的研究主题之一。人脸识别的目的是从人脸图像中抽取人的个性化特征，并以此来识别人的身份。一个简单的自动人脸识别系统，包括以下4个方面的内容 ：

     (1)人脸检测(Detection)：即从各种不同的场景中检测出人脸的存在并确定其位置。

     (2)人脸规范化(Normalization)：校正人脸在尺度、光照和旋转等方面的变化。或者叫做alignment，人脸对齐，人脸校准

    (3)人脸校验(Face verification )：采取某种方式表示检测出人脸和数据库中的已知人脸，确认两张脸是否是同一个人。

    (4)人脸识别(Recognition)：将待识别的人脸与数据库中的已知人脸比较，得出给你的脸是库里的谁。

2　人脸识别算法的框架

人脸识别算法描述属于典型的模式识别问题，主要有在线匹配和离线学习两个过程组成。

     在人脸识别中，特征的分类能力、算法复杂度和可实现性是确定特征提取法需要考虑的因素。所提取特征对最终分类结果有着决定性的影响。分类器所能实现的分辨率上限就是各类特征间最大可区分度。因此，人脸识别的实现需要综合考虑特征选择、特征提取和分类器设计。

在用静态图像或视频图像做人脸识别的领域中，国际上形成了以下几类主要的人脸识别方法：

    1）基于几何特征的人脸识别方法

     基于几何特征的方法是早期的人脸识别方法之一。常采用的几何特征有人脸的五官如眼睛、鼻子、嘴巴等的局部形状特征。脸型特征以及五官在脸上分布的几何特征。提取特征时往往要用到人脸结构的一些先验知识。识别所采用的几何特征是以人脸器官的形状和几何关系为基础的特征矢量，本质上是特征矢量之间的匹配，其分量通常包括人脸指定两点间的欧式距离、曲率、角度等。基于几何特征的识别方法比较简单、容易理解，但没有形成统一的特征提取标准；从图像中抽取稳定的特征较困难，特别是特征受到遮挡时；对较大的表情变化或姿态变化的鲁棒性较差。

    2）基于相关匹配的方法

     基于相关匹配的方法包括模板匹配法和等强度线方法。

     ①模板匹配法：Poggio和Brunelli专门比较了基于几何特征的人脸识别方法和基于模板匹配的人脸识别方法，并得出结论：基于几何特征的人脸识别方法具有识别速度快和内存要求小的优点，但在识别率上模板匹配要优于基于几何特征的识别方法。

     ②等强度线法：等强度线利用灰度图像的多级灰度值的等强度线作为特征进行两幅人脸图像的匹配识别。等强度曲线反映了人脸的凸凹信息。这些等强度线法必须在背景与头发均为黑色，表面光照均匀的前提下才能求出符合人脸真实形状的等强度线。

    3）基于子空间方法

     常用的线性子空间方法有：本征子空间、区别子空间、独立分量子空间等。此外，还有局部特征分析法、因子分析法等。这些方法也分别被扩展到混合线性子空间和非线性子空间。

Turk等采用本征脸( Eigenfaces)方法实现人脸识别。由于每个本征矢量的图像形式类似于人脸，所以称本征脸。对原始图像和重构图像的差分图像再次进行K-L变换，得到二阶本征空间，又称二阶本征脸。Pentland等提出对于眼、鼻和嘴等特征分别建立一个本征子空间，并联合本征脸子空间的方法获得了好的识别结果。Shan等采用特定人的本征空间法获得了好于本征脸方法的识别结果。    

Albert等提出了TPCA(Topological PCA)方法，识别率有所提高。Penev等提出的局部特征分析(LFA Local Feature Analysis)法的识别效果好于本征脸方法。当每个人有多个样本图像时，本征空间法没有考虑样本类别间的信息，因此，基于线性区别分析(LDA Linear Discriminant Analysis )，Belhumeur等提出了Fisherfaces方法，获得了较好的识别结果。Bartlett等采用独立分量分析(ICA，Independent Component Analysis)的方法识别人脸，获得了比PCA方法更好的识别效果。

    4）基于统计的识别方法

      该类方法包括有：KL算法、奇异值分解(SVD)、隐马尔可夫(HMM)法。

      ①KL变换：将人脸图像按行(列)展开所形成的一个高维向量看作是一种随机向量，因此采用K-L变换获得其正交K-L基底，对应其中较大特征值基底具有与人脸相似的形状。国外，在用静态图像或视频图像做人脸识别的领域中，比较有影响的有MIT的Media实验室的Pentland小组，他们主要是用基于KL变换的本征空间的特征提取法，名为“本征脸( EIgenface)。

②隐马尔可夫模型：剑桥大学的Samaria和Fallside对多个样本图像的空间序列训练出一个HMM模型，它的参数就是特征值；基于人脸从上到下、从左到右的结构特征；Samatia等首先将1-D HMM和2-D Pseudo HMM用于人脸识别。Kohir等采用低频DCT系数作为观察矢量获得了好的识别效果。Eickeler等采用2-D Pseudo HMM识别DCT压缩的JPEG图像中的人脸图像；Nefian等采用嵌入式HMM识别人脸。后来集成coupled HMM和HMM通过对超状态和各嵌入状态采用不同的模型构成混合系统结构。

     基于HMM的人脸识别方法具有以下优点：第一，能够允许人脸有表情变化，较大的头部转动；第二，扩容性好.即增加新样本不需要对所有的样本进行训练；第三，较高的识别率。

    5）基于神经网络的方法

      Gutta等提出了混合神经网络、Lawrence等通过一个多级的SOM实现样本的聚类，将卷积神经网络CNN用于人脸识别、Lin等采用基于概率决策的神经网络方法、Demers等提出采用主元神经网络方法提取人脸图像特征，用自相关神经网络进一步压缩特征，最后采用一个MLP来实现人脸识别。Er等采用PCA进行维数压缩，再用LDA抽取特征，然后基于RBF进行人脸识别。Haddadnia等 基于PZMI特征，并采用混合学习算法的RBF神经网络进行人脸识别。神经网络的优势是通过学习的过程获得对这些 规律 和规则的隐性表达，它的适应性较强。

     6）弹性图匹配方法

     Lades等提出采用动态链接结构(DLA，Dynamic Link Architecture) [32]的 方法 识别人脸。它将人脸用格状的稀疏图。

      该算法中的节点用图像位置的Gabor小波分解得到的特征向量标记，图的边用连接节点的距离向量标记。Wiskott等人使用弹性图匹配方法，准确率达到97.3%。Wiskott等将人脸特征上的一些点作为基准点，构成弹性图。采用每个基准点存储一串具有代表性的特征矢量，减少了系统的存储量。Wurtz等只使用人脸ICI部的特征，进一步消除了结构中的冗余信息和背景信息，并使用一个多层的分级结构。Grudin等也采用分级结构的弹性图，通过去除了一些冗余节点，形成稀疏的人脸描述结构。另一种方法是，Nastar等提出将人脸图像I(x，y)表示为可变形的3D网格表(x，y，I(x，y))，将人脸匹配问题转换为曲面匹配问题，利用有限分析的方法进行曲面变形，根据两幅图像之间变形匹配的程度识别人脸。

      7）几种混合方法的有效性

      (1)K-L投影和奇异值分解(SVD)相融合的分类判别方法。

      K-L变换的核心过程是 计算 特征值和特征向量。而图像的奇异值具有良好的稳定性，当图像有小的扰动时，奇异值的变化不大。奇异值表示了图像的代数特征，在某种程度上，SVD特征同时拥有代数与几何两方面的不变性。利用K-L投影后的主分量特征向量与SVD特征向量对人脸进行识别，提高识别的准确性 [37]。

       (2)HMM和奇异值分解相融合的分类判别方法。

      采用奇异值分解方法进行特征提取，一般是把一幅图像(长为H)看成一个N×M的矩阵，求取其奇异值作为人脸识别的特征。在这里我们采用采样窗对同一幅图片进行重叠采样，对采样所得到的矩阵分别求其对应的前k个最大的奇异值，分别对每一组奇异值进行矢量标准化和矢量重新排序，把这些处理后的奇异值按采样顺序组成一组向量，这组向量是惟一的。

综合上述 论文中的实验数据表明，如表1：

表1  人脸识别算法比较

方法

识别时间

识别率

基于SVM的方法

	0.32s	

94%

基于SVM+KL变换的方法

0.36s	

80%

基于特征脸的方法

0.32s	

95%

基于特征脸+Fisher线性变换的方法

0.36s	

82%

基于小波变换+BP神经网络的方法

0.12s	

89%

基于SVM+BP的方法

0.40s	

92%

基于HMM的方法

0.68s	

93%

基于HMM+SVM的方法

0.56

96%

    

8）基于三维模型的方法

     该类方法一般先在图像上检测出与通用模型顶点对应的特征点，然后根据特征点调节通用模型，最后通过纹理映射得到特定人脸的3D模型。Tibbalds 基于结构光源和立体视觉 理论，通过摄像机获取立体图像，根据图像特征点之间匹配构造人脸的三维表面。

      Zhao提出了一 个新的SSFS(Symetric Shape- from-Shading)理论来处理像人脸这类对称对象的识别问题，基于SSFS理论和一个一般的三维人脸模型来解决光照变化问题，通过基于SFS的视图合成技术解决人脸姿态问题，针对不同姿态和光照条件合成的三维人脸模型。

三维图像有三种建模方法：基于图像特征的方法、基于几何、基于模型可变参数的方法。其中，基于模型可变参数的方法与基于图像特征的方法的最大区别在于：后者在人脸姿态每变化一次后，需要重新搜索特征点的坐标，而前者只需调整3D变形模型的参数。三维重建的系统框图，如图1所示。



特征提取

特征提取

坐标，视场变换

坐标，视场变换

视频图像

视频图像



            



三维建模

三维建模

纹理映射

纹理映射

局部特征匹配

局部特征匹配

全局位置匹配

全局位置匹配





通用三维模型

通用三维模型





图1　三维建模的系统框图

      三维人脸建模、待识别人脸的姿态估计和识别匹配算法的选取是实现三维人脸识别的关键技术。随着采用三维图像识别人脸技术的发展，利用直线的三维图像信息进行人脸识别已经成为人们研究的重心。





4. 应用场景和应用水平的分析和比较

人脸识别的应用场景是非常宽泛的，现在主要两块，一个是金融行业，一个是安保行业。金融行业，已经从马云的蚂蚁金服演示中看到了场景，通过刷脸进行支付，显然刷脸可以付钱了，为什么不可以签收快递呢，下一步淘宝应该会把淘宝签收快递的功能打通。我相信有一天，我们会收到无人机送来的快递，无人机在你的面前拍一张照片，进行对比，就知道这个用户就是需要的用户，完成整个的支付过程。实际上这种场景，是经过多方面的讨论和认证的。基于这样的场景，是跟第三方的支付认证相关的，包括我们看到的腾讯的银行，第一张远程开卡，就是通过人脸识别的技术，把人证合一进行认证，这样远程开户，远程开卡的功能，在我们的券商，在我们的网络银行上面，应该有广泛的应用。
     对于安保行业来说，刷脸开门，现阶段，人脸识别的应用应该说达到了一个可具备商业化的水平，我们举个例子，在去年的时候，香港有一个导演叫许鞍华，他在南京地铁中丢了一个他的皮包，这个案件的破获，只花了5个小时。视频监控里面获取了一张照片截图，截到了嫌疑人的照片，是极其模糊的，侧脸的照片，如果肉眼比对，发现不了什么。但是有一家非上市公司，他们通过一个图像还原技术，把那个照片还原出可能嫌疑人的样子，清晰照，用这个照片到图库当中比对，锁定嫌疑人的身份，把嫌疑人抓获，只需要了5个小时的时间。现在安防领域的监控，我们可以看到各个省市以及地级市，都在上大量的视频监控，人脸识别的大平台。在整个安防的投入当中，上一代的安防只是静态的记录下来数据，但是下一代的安防，是对实时数据的采集、辨认，就是一个核心的技术，这个技术，人脸识别在其中发挥的作用是很大的。
     再拓展一下，未来的商业用途，到底有没有第二代人脸识别技术的潜在的应用的场景呢。我们说在未来，应该说原来整个确定身份的身份证，但是证和人的比对需要人工来完成。如果我们直接界定，达到了这样的一个标准，实际上每个人所对应的唯一的ID就是脸部的生物特征。这个识别了以后，所有的地方都可以用刷脸的方式，所有的地方都可以用刷脸去开门，用刷脸去做各种各样的事情。你刷脸的数据，包括你去坐火车、坐飞机、去哪儿吃饭、购物、收快递等等，这些数据都会掌握到人脸识别中，刷脸的数据将取代现在线上的点击量。现在信用卡、银行卡消费的数据，其实有助于知道用户消费习惯和消费数据，做大数据的营销和征信，但是刷脸时代来临之后，这个的价值更大了。有很多张卡，但是只有一张脸，这是唯一的。刷脸数据是2.0时代当中，我们重点看到的。



仍需挑战的方面 

经过四十多年的发展，尤其是近十年来的研究，人脸识别技术已经取得了长足的进步。目前最好的人脸识别系统在注册和认证环境条件比较一致、对象比较配合的情况下已经能够达到令人满意的效果。对1000人左右的识别系统，其正确识别率可以在95%左右；验证系统的等错误率性能也在2%以下。然而，这并不意味着人脸识别技术已经非常成熟了。恰恰相反，因为更大量的人脸识别应用系统需要在更大大规模人脸库、摄像环境不可控、对象不配合的情况下使用，即使是目前最好的识别系统在这样的情况下识别性能下降也非常快，很多情况下识别系统正确识别率陡降至75%以下，验证系统等错误率攀升到10%以上——这样的性能显然是应用系统用户根本无法接受的。因此，现有的人脸识别系统尤其需要有针对性地解决在非理想摄像条件下（光照变化、背景变化、摄像设备差异）和对象不配合（视角变化、表情变化、佩带饰物乃至化妆）时必然遇到识别性能下降问题。这些变化因素在不同的应用系统中均会有不同程度的出现，因而会极大地影响实用识别系统的性能，导致识别系统性能的下降。概括而言，目前人脸识别领域面临的主要挑战包括：鲁棒性、准确的特征配准问题，对各种图像采集条件变化鲁棒的核心识别算法，识别算法的泛化能力和自适应学习问题，光照变化问题，尤其是室外光照变化，姿态不变的人脸识别算法，人脸信息采集设备带来的问题，低质量照片的检测识别问题，年龄变化导致的照片老化问题，墨镜、帽子、口罩等造成的遮挡问题，化妆、整容带来的问题。而且上述挑战并不是单独作用的，例如姿态和光照问题同时出现，会更进一步地增加问题的难度。



结束语  

人脸识别是一项既有科学研究价值，又有广泛应用前景的研究课题。国际上大量研究人员几十年的研究取得了丰硕的研究成果，自动人脸识别技术已经在某些限定条件下得到了成功应用。这些成果更加深了我们对于自动人脸识别这个问题的理解，尤其是对其挑战性的认识。尽管在海量人脸数据比对速度甚至精度方面，现有的自动人脸识别系统可能已经超过了人类，但对于复杂变化条件下的一般人脸识别问题，自动人脸识别系统的鲁棒性和准确度还远不及人类。这种差距产生的本质原因现在还不得而知，毕竟我们对于人类自身的视觉系统的认识还十分肤浅。但从模式识别和计算机视觉等学科的角度判断，这既可能意味着我们尚未找到对面部信息进行合理采样的有效传感器（考虑单目摄像机与人类双眼系统的差别)，更可能意味着我们采用了不合适的人脸建模方法（人脸的内部表示问题），还有可能意味着我们并没有认识到自动人脸识别技术所能够达到的极限精度。但无论如何，赋予计算设备与人类似的人脸识别能力是众多该领域研究人员的梦想。相信随着研究的继续深入，我们的认识应该能够更加准确地逼近这些问题的正确答案。 计算所人脸识别课题组经过多年努力，终于逐渐进入了国际人脸识别竞争的第一方阵。我们提出的新颖算法、完成的高效识别系统也逐渐得到了国内外同行的认可。但我们也必须清醒地看到，在人脸识别领域，其实很难说谁的算法就比别的算法真正地好了多少。而且众多的研究人员正在加入进来，逆水行舟，慢进则退。我们必须付出更多的艰辛才能真正在算法和系统两方面超越前人，取得更大的研究成果！