人工智能报告







       姓名：宋燕军 

       学号：117106010743






摘要

人脸识别技术应用广泛，已成为多个学科领域的研究热点之一。本文简要介绍了几种针对二维人脸图像的人脸识别算法。针对目前遇到的人脸识别的挑战，如低分辨率、光照变化、表情以及姿势等给出多位研究人员的解决方案。对于目前人脸识别的研究方向——三维人脸识别，本文也作出了简要论述。



第1章 绪论

1.1 研究的背景与意义

人脸识别技术作为生物特征识别领域中一种基于生理特征的识别，是通过计算机提取人脸特征，并根据这些特征进行身份验证的一种技术。如果将基于生理特征的识别作为商业化应用，人脸识别只是其中的一个备选方案。如果识别从精准度的角度和不可替代的角度来说，最精准的是虹膜识别，然而，虹膜的识别采集成本非常高，识别的效率相对不是很高并且需要人的行为配合因而不适合大范围推广。而对于目前使用较为广泛的指纹识别，尽管指纹的唯一性较强同时采集成本较低，但是指纹较容易被复制，是静态图像的对比，因此安全性较低。因此人脸识别技术在全球范围内兴起。目前，人脸识别技术在公安（罪犯识别等）、安全验证系统、信用卡验证、医学、档案管理、视频会议、人机交互系统等方面具有巨大的应用前景。

1.2发展历程与国内外研究现状

   自动人脸识别系统的研究始于20世纪中期，早期的人脸识别主要依靠一些手工标定的几何特征（如眼睛，嘴巴等器官的位置，距离）进行分类，并没有太多成果。而后1991年发表的特征脸（EigenFace）的方法通过主成分分析（PCA）将图像投影到一个低维的“特征空间”，使得信息损失最少，在该“特征空间”上进行人脸分类。由于光照、姿态、表情等因素会直接影响人脸识别率，于是在单人单张的人脸条件下，产生了许多校正算法。 研究人员主要有两种思路来应对这些不利因素，一是进行专门的校正（去光照以及降低光照的影响，3D校正以降低姿态的影响），二是寻找鲁棒特征。因此在进入21世纪后，人脸识别将更多精力放在提高算法鲁棒性上，其中较常用的包括Gabor特征、LBP特征。2007年包含复杂姿态，表情、遮挡等变化的LFW数据集被建立，旨在评价非约束场景下的人脸识别性能。但是到2010年左右，最好的算法也只有85%左右的准确性。于是从2010年开始，准确的特征点定位、高层特征表示与度量学习、收集更多的训练样本成为人脸识别研发的方向。一个代表性的算法就是微软的HDLBP算法，该方法基于准确定位的特征点提取高维的人脸特征，以及稀疏投影的方式进行降维，最后通过一种度量学习来计算相似度，在LFW上取得了93％以上的准确率，此外，通过大量外部数据集的训练，准确度还可提升至95%。2012年以后，人脸识别已进入了深度学习时代。虽然在一开始的一些尝试中，深度学习在人脸识别上并没有取得非常领先的结果，但经过一系列的改进之后，在2014年的CVPR上，Facebook、CUHK、Face++等通过深度学习在LFW上取得了97%以上的准确率，尤其是CUHK的汤晓鸥实验室对其DeepID2算法取得了99%以上的准确率，第一次使得算法的性能在LFW数据集上超过了人类[1]。毫无疑问，深度学习成为目前人脸识别领域最主流的研究方向。

    美国是人脸识别技术起步最早的国家。早在1993年，美国国防部就启动了FERET项目, 为其之后的生物智能识别技术奠定了基础, 推动人脸识别技术从初始阶段提升到原型系统阶段。在2014年 FBI推出他们的“新一代身份识别数据库” (NGI) ，利用监控锁定犯罪嫌疑人，从而进行全网追捕。而在最近苹果公司发布的最新产品IphoneX中的人脸识别FaceID，则利用人脸的三维信息来识别人脸从而进行解锁。

我国人脸识别的起步较晚，但是发展较快。从2001年开始，公安部门就开始使用这一技术来防范打击重大刑事犯罪并取得国家的支持；2008年奥运会的开、闭幕式上应用了人脸识别技术进行安保，而在上海的世博会上，该技术也得到广泛应用；而关于移动端支付，马云曾在德国汉诺威展上就已经展示过刷脸支付。

1.3 主要研究内容

人脸识别技术从最初对背景单一的正面灰度图像的识别，经过对多姿态（正面、侧面等）人脸识别的研究，发展到能够动态实现人脸识别，目前正在向三维人脸识别的方向发展[2]。人脸识别技术主要通过三个步骤完成，即人脸检测定位、面部特征提取和人脸对比确认。本文主要基于二维图像对第三步人脸对比确认的方法进行综述，分类介绍目前较为常用的人脸识别算法以及简要介绍三维人脸识别技术，并在展示一些目前人脸识别的研究实例。

第2章 常用的人脸识别技术

2.1 基于几何特征的方法

    基于几何特征的方法[3]时最早，最传统的方法。它是基于部件的方法，通常需要与其他算法结合才能有比较好的效果。目前这类方法也有不少。如根据几何特征曲率对人脸进行分类及识别[4]和基于面部几何特征点提取的人脸识别方法[5]等。

	   （1）根据几何特征曲率对人脸进行分类识别是通过轮廓线曲率分类的。经过人脸图像的预处理后，提取出人脸轮廓得到轮廓线。然后对此轮廓线逐点计算曲率得到曲率线并建立一个分类库。将不同的曲率线之间的互相关函数定义为曲率线之间的相似性，并由此对人脸进行识别和分类。本方法对质量较好的人脸图像有较好的分类与识别效果，而对某些质量较差的图像，人脸轮廓线的提取效果不太理想。

   （2）基于面部几何特征点提取的人脸识别方法。这种方法首先利用特征点（包括眼睛、鼻子、嘴巴、下巴等）构造出待识别的人脸的特征向量，这些特征向量具有位置、视点、大小等不变性，然后将此特征向量与样本库中的人脸特征向量相比较，计算两者的相似度来完成识别。该方法对于光照变化与姿态变化并不敏感。

2.2 基于代数特征的方法

    基于代数特征的方法将人脸图像视为随机向量，从而用一些代数方法来分析人脸模式，主要有特征脸方法[6]、奇异值分解方法（Singular Value Decomposition，SVD）[7]等。

   （1）特征脸方法是从主量分析方法（PCA）导出地一种人脸识别技术。PCA方法最早由irovitch和Kirby[8]引入人脸识别领域。在20世纪90年代出，由Turk和Pentland[9]提出地特征脸方法是该类别中最具代表性的方法，开创了人脸识别领域地新局面。特征脸方法地基本思想是将图像经过KL变幻后由高维向量转化为低维向量，并形成低维线性向量空间，人脸投影到这个低维空间所得到地投影作为识别的特征矢量。特征脸方法的不足之处是受表情变化、光照角度强度变化和视角变化等严重影响，鲁棒性较差。因此研究人员在此方法上进行改进，如将特征脸与线性判别函数[10]相结合的方法、特征半脸方法等[11]。

   线性判别函数的表达式为，其中X是d维特征向量的样本，W是权重，是阈值权。此判别函数是d维特征空间中某个X点到超平面的距离。线性判别分析方法选择以类内散布正交的矢量作为特征脸空间，从而可以控制图像之间与识别无关的差异，同时弱化了统一人脸由于光照、视角和表情引起的变化，获得了比特征脸更好的识别效果。

   特征半脸的方法是根据人脸的上半部分特征对于识别所起的作用要比下半部分特征大。人的表情发生变化时, 上半部分脸变化较小, 而下半部分脸变化较大这一特征来实现的。将人脸图像分成上下两部分, 并分别应用特征脸方法, 采用不同权值的以容忍一定程度的表情变化。

   （2）奇异值分解方法。奇异值特征是一种反映图图像本质属性的代数特征。在某种程度上，奇异值特征具有代数和几何上的双重稳定性，还具有比例不变性、旋转不变性等重要性质，因此将人脸图像矩阵进行奇异值分解可以很好地提取出图像地代数特征，然后进行匹配识别。

2.3 基于模版

    基于模版的方法最为典型的是基于弹性图匹配的方法[12]。弹性图匹配方法在二维空间上为人脸建立属性拓扑图，图中边表示了人脸各个器官之间的拓扑结构，它对于人脸变形具有一定的容忍度，图中的每个顶点表示一个特征向量，用来记录人脸在该顶点附近的特征信息，然后利用弹性匹配法将库中人脸和待识别人脸的弹性图进行匹配，找到匹配程度最高的一个人脸图像。由于特征向量的定义方式多种多样，弹性图的匹配方法也是多样的，如基于Gabor小波变换的弹性图匹配方法[13]，它利用Gabor函数定义特征向量，得到的弹性图如图1所示，它对人脸较小角度的旋转以及光照角度的改变等都有较好的容忍性，但是于特征脸识别方法相比识别速度较慢。

                  

                    图1基于Gabor小波变换的人脸弹性图

2.4 基于深度学习

      深度学习算法种类繁多，人脸识别应用较广的方法主要是卷积神经网络（Convolutional Neural Networks，CNN）。它是一种非全连接的神经网络结构，基本结构包括两层，其一为特征提取层，每个神经元的输入与前一层的局部接受域相连，并提取该局部特征。其二是特征映射层，网络的每个计算层由多个特征映射组成，每个特征映射就是一个平面，平面上所有的神经元权值相等。将CNN应用于人脸识别的理论基础在于图像的空间联系为局部像素联系较紧密而距离较远相关性则越弱，因而神经元只需对局部图像进行感知。

目前，利用深度学习作为人脸特征点定位的经典研究之一是CVPR2013中汤晓鸥课题组的工作[14]，利用级联深度卷积网络进行面部特征点定位。它提出一种通过3级卷积神经网络估计脸部关键点的新方法。在每一级，网络的输出都是鲁棒且准确的。卷积网络的深度结构更在初始阶段中从全部的脸部区域中提取出高级特征，这些有利于关键点的准确定位。网络的后两级则被训练用于局部优化初试预测值（如图2所示）。



            图2 深度卷积网络F1的结构1



第3章 复杂场景下的人脸识别应用

    传统人脸识别算法假定输入的人脸图像具有较好的分辨率，然而在实际生活中，由于目标人脸常常与摄像距离较远，又受到光照条件变化、目标人脸的运动模糊以及设备自身的噪声的因素等影响，人脸图像的噪声往往很大。针对这种情况，已有大量研究人员开展相关工作，解决复杂场景下的人脸识别。

3.1 低分辨率情况下的人脸识别

    从工程意义上说，低分辨率与高分辨率图像之间存在一定的转换关系。把一张图像看成一个矢量，从高分辨率图像到低分辨率图像的过程可以用式子表示，其中D表示模糊和下采样的过程，表示图像采集过程中的噪声扰动。从低分辨率图像到高分辨图像实际上就是一个超分辨率增强（Super-Resolution,SR）的过程，可以用式子表示。从远离上说，D与S应该是可逆的过程，但是由于信息的确实，两个过程并不完全可逆，对与低分辨率图像的超分辨率增强本身就是一个病态的过程[15]。根据以上两种模式转换，可以得出一下两种解决低分辨人脸识别的问题的思路：





分别表示对高分辨率基准样本进行下采样和对低分辨率测试样本进行超分辨率增强，然后进行距离测度比较，得到最小距离所对应的测试样本类别，其中d表示距离测度，c表示样本类别。图3[16]给出了高分辨与低分辨人脸识别系统对比

   

目前主要将低分辨率人脸识别算法分为两类：超分辨率增强方法与分辨率稳健特征表达方法。

（1）超分辨率增强：首先对低分辨率图像进行增强得到高分辨率图像，然后利用传统的高分辨率识别方法进行识别。Baker[17]等提出“人脸幻想”的概念，对人脸图像进行金字塔分解得到母结构，建立高分辨率像素之间的关系，在最大后验（Maximum A Posteriori，MAP）概率的框架下实现超分辨率重建；FreeMan[18]等提出一种基于马尔可夫模型的超分辨率识别算法，对训练库中高分辨率图片与低分辨率图片见的不同区域间的细节信息进行学习，然后利用学习到的关系预测低分辨率图片的细节信息；Yang[19]等提出了一种基于稀疏编码的学习方法对低分辨率图片进行超分辨率重建，其主要特点是建立稀疏字典进行学习，然而由于使用线性规划求解，计算速度较慢。

（2）分辨率稳健特征表达：直接从低分辨率人脸图像上提取由鉴别性的信息特征。大部分在高分辨率人脸识别系统中有效的特征，可能在低分辨率条件下就会失效，因此，寻找分辨率稳健组合特征非常困难。Choi[20]等人采用颜色特征如RQCr空间和不同颜色空间的组合，用于低分辨率人脸识别。由于颜色特征对于关照变化较敏感，这将是其应用的一大障碍。此外。Lei[21]等人基于局部二值模式（LBP）和傅立叶变换，提出一种称为局部特征描述子的纹理特征；Abiantun[22]等人利用核关联特征分析方法处理低分辨率特征提取问题。

3.2 光照变化

   由于光照会改变人脸图像灰度的相对分布，所以光照变化会对人脸识别的结果产生很大影响。许多学者对光照变化的处理以达到较深入的水平，目前已经出现了处理光照变化的方法，大致可以分为3类：

寻找对于光照变化不敏感的人脸图像表示方法

    虽然对于Lambertian表面而言，严格来说并不存在不受光照影响的表示方式，但确实存在某些对光照相对不敏感的图像表示方法。Chen等人[23]利用图像梯度方向来提供光照不敏感的图像表示。Adini[24]等人认为使用对于光照变化不敏感的图像特征能够克服光照条件改变引起的图像的变化，比如图像边缘、灰度导数以及图像二维Gabor滤波器的卷积等等。但次方法在追求光照不变性特征时忽略了灰度值这一重要信息，从而弱化了人脸图像中包含的个体特征信息。Shashua等人[25]提出用商图像（Quotient Image）方法来处理光照变化问题。在物体无法满足无阴影的Lambertian模型假设时，他们推导出：测试图像与三幅不共面光照图像的线性组合之间的商图像只反映了与光照无关的纹理信息。商图像的缺点时当存在阴影时，算法会失效。所以，这类方法因为忽略了图像灰度值这一重要信息，而不能从根本上解决光照变化问题。

对传统人脸识别算法进行改进和推广

     Belhumeur等[26]通过实现证明：当存在光照变化时，在特征脸识别方法中，丢弃最前面的几个主成分可以取得更好的识别效果。然而，这种处理方法的前提时要保证最前面几个主成分的方法是由光照造成的。W.J.Li等[27]采用多特征空间的思想来解决光照变化问题，为每一个特定的光照方向建立一个特征空间，然后基于多特征空间提出了三种多光照方向人脸识别方法，实验证明基于多特征空间的方法具有较好的识别性能。但缺点是每人每一光照方向需要多兆训练样本。

构建图像合成模型

图像合成模型即对光照进行建模，可以合成与测试图像具有相同或相似光照条件的新图像作为数据库中的图像。H.T.Wang[28]等提出了一个对不同光照条件下的人脸图像进行分析和建模的通用框架。介绍了在光照变化条件下人脸建模的几个概念：人脸光照空间、通用人脸模型和通用人脸成像模型。从理论上证明了人脸光照子空间可以由至少三幅人脸图像构造，任意人脸图像的光照可以表示成子空间中的一点。光椎体的极限覆盖了整个光球体，因戏通过稀疏采样得到的人脸图像可以构造人脸模型，进而提出了光照调整（Illumination Alignment）算法。这类方法的主要缺点是为了获得较好的合成效果，需要多张训练样本并且通过引入光照，使得整个分类问题增加了一维。

3.3 剧烈人脸图像变化

    传统的人脸识别算法在遮挡、表情、姿势等变化下的单样本人脸识别条件下会遇到很大困难，比如基于训练学习方法的识别性能将会受到严重影响甚至不能工作或者基于全局特征的识别性能也会下降。基于这些问题，文献[29]提出基于稀疏的局部特征的方法来解决各种变化下的单样本识别问题。它主要针对SIFI算子在人脸识别中的应用，提出一种更适合人脸识别稀疏局部特征描述子（FSD）。

第4章 三维人脸识别及应用

4.1 三维人脸识别简介

从上面的介绍来看，基于图像的二维识别技术日趋成熟，在一定的约束条件下能够取得较好的识别成果，但是由于光照、姿态、表情、年龄等变化显著地降低了二维人脸识别算法地性能，于是更多研究人员致力于利用人脸地三维信息来进行识别。原因是人脸地三维信息能够更精确地描述人地脸部特征，提取地某些特征具有刚体变换不变性，并且不易受姿势以及光照的影响。以下简要介绍三类三维人脸匹配算法。

基于空域直接匹配的方法

    基于空域直接匹配方法不提取特征，直接进行曲面相似度匹配，常用的方法由迭代最近点法（iterative closest point，ICP）和Hausdroff距离法等。ICP方法最早几乎同时由Chen[30]、Besl等[31]分别独立地提出，用于曲线或曲面片段地配准。基于ICP地识别方法中地配准误差是2个点集之间的平均距离，Hausdroff距离定义了点集之间的另一种距离度量[32]，它同样可以作为人脸模型间的差别度量。Hausdroff距离需要在2个对齐的人脸模型间计算，距离越小越相似。

基于局部特征的匹配

特征是从一个对象中提取的、在一定条件下保持稳定变得属性，其本质可以看作对一个对象的信息进行压缩或其他变换处理。对三维人脸识别而言，最好还要求特征能够在人脸模型的旋转、平移、镜像变换下保持不变。三维人脸识别的局部特征主要包括1）局部描述符：用曲面上某点领域内曲面的几何信息或几何统计信息描述该点的局部特征；2）脸部曲线特征：将人脸曲面形状特征用若干从曲面提取来的二维曲线近似表示；3）基于曲率特征：配合使用其他方法对脸部曲线进行关键点提取、区域分割等处理。

基于整体特征的匹配

该类方法注重三维模型的整体特征，主要分为1）将三维人脸统一用深度图表示，直接使用基于表观的方法；2）将三维人脸映射为EGI（extended Gaussian image）[33]，然后匹配EGI；3）整体变换三维模型后再做匹配。

4.2 IphoneX中的三维人脸识别 

   苹果公司新发布的产品IphoneX中加入了人脸识别解锁功能。它利用在手机上配备的前置3D摄像头进行人脸的扫描识别。主要利用红外技术手段获取人脸三维信息，运作方式为一个系统中一个模块对物体发出红外点，以便根据那些点的大小和扭曲度来收集物体深度方面的信息。这些深度信息能够弱化光照变化、角度、遮挡等问题，适应多变的光照条件与夸张的表情变化。



第5章 总结

     本文对人脸识别的发展历程以及主要技术进行了综述。主要介绍了在二维人脸图像下的人脸识别技术，并且针对低分辨率、光照变化、剧烈人脸变化情况下的人脸识别解决方法做出简要分析。对于目前以及将来人脸识别的新的方向3维人脸识别也做出了简要说明。人脸识别前景广阔，应用场景十分广泛，对于一些复杂环境下人脸识别的更好的解决方法还值得我们继续探索。

参考文献：

[1] 汪海洋. 人脸识别技术的发展与展望[J]. 中国安防, 2015(21):62-65.

[2] 肖冰, 王映辉. 人脸识别研究综述[J]. 计算机应用研究, 2005, 22(8):1-5.

[3] CHING-WEN CHEN, CHUNG-LIN HUANG. HUMAN FACE RECOGNITION FROM A SINGLE FRONT VIEW[J]. International Journal of Pattern Recognition & Artificial Intelligence, 1992, 6(04):571-593.

[4]凌旭峰, 杨杰, 杨勇. 基于轮廓线曲率特征的人脸分类及识别[J].红外与激光工程,1999,28(4):37-39.

[5]张俊,何昕,李介谷.基于面部几何特征点提取的人脸识别方法[J] . 红外与激光 工程 , 1999 , 28(4):40-43 .

[6]M Turk, A Pentland. Face Recognition Using Eigenfaces[C] . IEEE Conf. onCVPR,Maui,Hawaii,1991.586-591.

[7]周德龙, 高文, 赵德斌.基于奇异值分解和判别式 KL投影的人脸 识别[J] .软件学报,2003,14(04):783-789.

[8]Kirby M, Sirovich L. Application of the Karhunen-Loeve procedure for the characterization of human faces[J]. IEEE Transactions on Pattern Analysis & Machine Intelligence, 2002, 12(1):103-108.

[9]Turk M, Pentland A. Eigenfaces for Recognition. J Cogn Neurosci[J]. Journal of Cognitive Neuroscience, 1991, 3(1):71-86.

[10]边肇祺,张学工,等.模式识别(第2版)[M].北京:清华大学出版社 , 2000 .

[11]高丽萍, 郭义民, 倪重匡. 一种改进的特征脸方法[J].计算机应用与软件 , 2002 , 44-47 .

[12]Laurenz, Wiskott, Jean Marc Fellous, Norbert Kruger, et al. Face Recognition by Elastic Graph Matching[J] . IEEE Transactions on Pattern Analysis and Machine Intelligence,1997,19(7):775-779.

[13]Lades M, Vorbruggen J C, Buhmann J, et al. Distortion Invariant Object Recognition in the Dynamic Link Architecture[J]. IEEE Transactions on Computers, 1993, 42(3):300-311.

[14] Sun Y, Wang X, Tang X. Deep Convolutional Network Cascade for Facial Point Detection[C]// Computer Vision and Pattern Recognition. IEEE, 2013:3476-3483.

[15] Zou W W W, Yuen P C. Very Low Resolution Face Recognition Problem[J]. IEEE Transactions on Image Processing A Publication of the IEEE Signal Processing Society, 2012, 21(1):327-40.

[16] 王智飞. 低分辨率人脸识别算法研究[D]. 北京交通大学, 2013.

[17] Bartlett M S, Movellan J R, Sejnowski T J. Face Recognition by Independent Component Analysis[C]// IEEE Transactions on Neural Networks. 2002:1450-1464.

[18]山世光. 人脸识别中若干关键问题的研究[D]. 中国科学院研究生院(计算技术研究所), 2004.

[19]李铭. 自动人脸检测与识别系统中若干问题的研究[D]. 北京交通大学, 2005.

[20]Choi J Y, Yong M R, Plataniotis K N. Color Face Recognition for Degraded Face Images[J]. IEEE Transactions on Systems Man & Cybernetics Part B Cybernetics A Publication of the IEEE Systems Man & Cybernetics Society, 2009, 39(5):1217-30.

[21] Lei Z, Ahonen T, Pietikäinen M, et al. Local frequency descriptor for low-resolution face recognition[C]// IEEE International Conference on Automatic Face & Gesture Recognition and Workshops. IEEE, 2011:161-166.

[22] Abiantun R, Savvides M, Kumar B V K V. How Low Can You Go? Low Resolution Face Recognition Study Using Kernel Correlation Feature Analysis on the FRGCv2 dataset[C]// Biometric Consortium Conference, 2006 Biometrics Symposium: Special Session on Research at the. IEEE, 2006:1-6.

[23] Chen H F, Belhumeur P N, Jacobs D W. In Search of Illumination Invariants[C]// Computer Vision and Pattern Recognition, 2000. Proceedings. IEEE Conference on. IEEE, 2000:254-261 vol.1.

[24]Moses Y, Adini Y, Ullman S. Face recognition: the problem of compensating for changes in illumination direction[C]// European Conference on Computer Vision. Springer-Verlag New York, Inc. 1994:286-296.

[25]Shashua A, Riklinraviv T. The Quotient Image: Class-Based Re-Rendering and Recognition with Varying Illuminations[J]. Pattern Analysis & Machine Intelligence IEEE Transactions on, 2001, 23(2):129-139.

[26]Belhumeur P N, Hespanha J P, Kriegman D J. Eigenfaces vs. Fisherfaces: recognition using class specific linear projection[J]. IEEE Transactions on Pattern Analysis & Machine Intelligence, 2002, 19(7):711-720.

[27]Li W J, Wang C J, Xu D X, et al. Illumination Invariant Face Recognition Based on Neural Network Ensemble[C]// IEEE International Conference on TOOLS with Artificial Intelligence. IEEE, 2004:486-490.

[28]Wang H, Li S Z, Wang Y, et al. Illumination modeling and normalization for face recognition[C]// IEEE International Workshop on Analysis and Modeling of Faces and Gestures. IEEE Computer Society, 2003:104.

[29]王昱, 陈志远. 复杂场景下智能人脸识别应用研究[J]. 通讯世界, 2016(15):258-259.

[30] Chen Y, Medioni G. Object modeling by registration of multiple range images[C]// IEEE International Conference on Robotics and Automation, 1991. Proceedings. IEEE, 2002:145-155.

[31] Besl P J, Mckay N D. A Method for Registration of 3-D Shapes[M]. IEEE Computer Society, 1992.

[32] Huttenlocher D P, Klanderman G A, Rucklidge W A. Comparing Images Using the Hausdorff Distance[J]. IEEE Transactions on Pattern Analysis & Machine Intelligence, 1993, 15(9):850-863.

[33] B. K. P. Horn. Extended Gaussian images[J]. Proceedings of the IEEE, 1983, 72(12):1671-1686.

注1: 阐述了F1的结构，包括4个卷积层，后面跟着是max pooling层，还有2个全连阶层。EN1和NM1使用相同的深度结构，由于输入区域的大小不同，每一层的大小不同。第2、3级的网络把预测点局部的一小块作为输入，且只允许在之前的预测上做微小改变。小块的大小和搜索范围随着级数减小。后两级的预测是被严格限制的，因为局部的图像有时是不可靠的。在后两级，每个点的预测位置是由两个取不同的patch大小的网络的平均值得到的。第一级的目标是稳定地估计关键点位置，同时保证极少的大误差。网络的后两级目标是得到高精度。后两级的所有网络使用一个相同的浅层结构。