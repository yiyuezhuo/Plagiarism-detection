课程报告









            课程：        人工智能原理与方法          

            题目：   文字识别的研究及产业应用情况     

            姓名：             郑睿莘                 

            学号：          117106021934              









2017．11．27

文字识别研究的主要内容和意义

和其他信息载体相比，文字具有占据空间小，信息量大，便于保存和传播的优点，可以使信息在时间和空间上得以迅速传播。在日常生活与工作中，商业往来、学术交流，出版印刷、大数据等等领域，都有着海量文字识别的需求，在最起初的时候，这种文字识别的主要工作都是交给人工完成，但是随着采集方法进步和实际需求的几何级膨胀，人力识别已远远不能满足实际的需求，成本也十分高昂。于是，使用计算机辅助等方法进行自动化文字识别的技术逐渐被发展出来，并投入更广阔的应用领域。

目前所指的文字识别，通常所指光学文字识别（OCR），其定义为：将所输入的手写或打印的文本图像使用机械或电子方法转换为机器编码的文本。这是一种将印刷文本数字化的常用方法，无论是从扫描的文档，文档的照片，场景照片（如风景照片中的标志和广告牌上的文字）还是叠加在图像上的字幕文本（例如来自电视广播），都可以使用OCR方法进行识别。将这些文本数据化后，可以对其进行编辑，检索，压缩存储等等处理。同时可以将这些文本和图像数据用于认知计算，机器翻译，TTS（文本到语音），关键数据和文本挖掘等等工作。

目前，文字识别的主要研究领域为模式识别，人工智能与计算机视觉。



文字识别研究历史与现状

早在1929年，奥地利科学家Tausheck最先提出光学文字识别这个概念，他发明了第一台被称为“阅读机”的OCR设备，当文字与事先储存的内容模板相对应时，光电传感器将光线指向文字。后来美国科学家Handel也提出了利用技术对文字进行识别的想法，但是这个想法直到现代计算机出现才得以实现。

二十世纪50，60年代，OCR的研究开始在世界各地起步。而研究的初期，多以文字的识别方法研究为主，且识别的文字仅为0至9的数字，逐渐再发展为识别字母。

第一个OCR软件是出现在1957年的ERA（Electric Reading Automation）。它是一种基于窥视孔方法的OCR实现，识别的速度是每秒120个英文字母。

几年后，第一代OCR产品纷纷面世，NCR公司、Farrington公司、IBM公司等分别研制出了自己的OCR软件。最早的OCR产品为IBM公司的IBM1418。它只能识别指定印刷体字体的数字、英文字母及部分符号。60年代末，日本的HITACHI公司和FUJITSU公司也分别研制出各自的OCR产品。

第二代OCR产品是基于手写体字符的识别，前期只限于手写体数字的识别，从时间上来看，60年代中期到70年代初期，第二代OCR产品逐渐问世。IBM公司于1965年，在“纽约世界博览会”上展出了其OCR产品－IBM1287。在日本，OCR的基本识别理论研究在1960年左右开始起步，初期以数字为对象，直至1965至1970年之间开始有一些简单的产品。日本TOSHIBA公司研制出了第一个实现手写体邮政编码识别的信函自动分拣系统，两年后NEC公司也推出了同样的系统。到1974年，使用该系统的信函分拣率达到92％～93％。在其他领域也得到了广泛应用。

而最早对印刷体汉字识别进行研究的是IBM公司的Casey与Nagy，1966年他们发表了第一篇关于汉字识别的论文，采用了模板匹配法识别了1000个印刷体汉字。

20世纪70年代初，日本的学者们着手进行汉字识别的研究，并做了大量的工作。中国在OCR技术方面的研究工作起步较晚，在70年代才开始对数字、英文字母及符号的识别进行研究，70年代末开始进行汉字识别的研究，到1986年汉字识别的研究进入一个实质性的阶段，不少研究单位相继推出了中文OCR产品。早期的OCR软件，由于识别率及产品化等多方面的因素，未能达到实际要求。同时，受制于当时硬件设备的性能和价格，OCR软件实用性并不高。只有个别部门，如信息部门、新闻出版单位等使用了OCR软件。

1986年以后我国的OCR研究有了很大进展，在汉字建模和识别方法上都有所创新，在系统研制和开发应用中都取得了丰硕的成果，不少单位相继推出了中文OCR产品。

进入20世纪90年代以后，随着平台式扫描仪的广泛应用，以及我国信息自动化和办公自动化的普及，大大推动了OCR技术的进一步发展，使OCR的识别正确率、识别速度满足了广大用户的要求。

进入21世纪，计算机硬件的进步推动了OCR技术的进一步发展，许多受制于当年硬件的算法都逐步登上舞台，OCR走向了一个全新的时代。



文字识别的技术流程与算法原理

一般的文字识别流程分为一下步骤：

图像输入：读入需要识别的光学图像信息，可能有许多不同的采样与储存方式，所需的读入办法也各种各样，但这个步骤要保证读入后图像信息格式的统一，从而便于后续处理。

预处理：预处理手段主要包括二值化、正规化、去噪、倾斜校正等。

二值化：随着采集手段的进步与多样化，采集到的图像信息也多种多样。其中主流手段为扫描与拍摄，录入的均为RGB的彩色图像（也有可能为压缩格式），彩色图像的信息量较大，但是对于文字识别任务来说，大部分信息是多余的。所以一般会对图片处理，仅留下灰度信息，然后使用预设的阈值处理所有像素为0/1，仅留下黑白信息。　

噪声去除：对于不同的文档，我们对噪声的定义可以不同，根据噪声的特征使用相应的算法进行去噪，就叫做噪声去除。

倾斜校正：录入文字信息时，根据录入手段的不同难免会出现文字相对于图像出现旋转或倾斜的情况，需要进行校正。

字符切割：预处理完毕的图像需要将字符单独切割出来送入识别算法中进行识别，否则算法无法正常工作。当然也存在端到端的生成模型，无需切割。不过这个是深度学习发展起来之后才出现的的模型，会在下文讨论。

字符识别：字符识别是整个文字识别工作中的核心步骤。该步骤将预处理完毕的字符图像送入识别算法。识别算法的种类繁多，其性能表现直接决定了文字识别的效果，如贝叶斯方法、支持向量机（SVM）、深度神经网络等等。



下面介绍主要的几种识别算法：

贝叶斯方法：

贝叶斯方法是一种典型的基于统计方法的分类模型，其利用先验信息和样本数据，确定事件的后验概率。当各类样本近似于正态分布时，贝叶斯可以算出错误率最小的分界面，并给出相应的分界面方程。因此，如果训练样本处于近似正态分布，可以用贝叶斯决策方法来设计分类器。贝叶斯网络能实现对调查结果的可能性加以数量化的评价，与传统欧式距离相比有更高的识别效率，但它需要的样本多，分析计算较复杂。另外，K-邻近方法是从贝叶斯决策出发估计条件概率密度的方法，该方法虽然实现简单，但存储量和计算量都太大，在样本规模不太大的时候也经常使用。



神经网络方法：

神经网络是一个非线性动态系统，这种分类识别方法依赖于统计特征和训练样本。早在1958年，Rosenblatt发明了感知机模型，掀起了第一波神经网络的热潮，但很快因为该模型被证明仅能进行线性分类，连XOR运算都无法模拟，进入了发展冰河期。1986年，Hinton发明了适用于多层感知器（MLP）的BP算法，并使用了Sigmoid作为激活函数引入了非线性映射，有效解决了非线性分类和神经网络训练问题，引发了神经网络第二次热潮。1989年，科学家从数学上证明了，对于任意一个闭区间内连续函数f，都可以用一个含有一个一个隐含层的BP网络来进行逼近。也是在1989年，LeCun发明了卷积神经网络-LeNet，并将其用于数字识别，且取得了较好的成绩，不过当时并没有引起足够的注意。1991年，BP算法被指出存在梯度消失问题，即在误差梯度后向传递的过程中，后层梯度以乘性方式叠加到前层，由于Sigmoid函数的饱和特性，后层梯度本来就小，误差梯度传到前层时几乎为0，因此无法对前层进行有效的学习，该发现对此时的NN发展雪上加霜。直到21世纪，随着硬件设备带来的计算能力的巨量提升，神经网络又一次走到台前，并且随着Relu激活函数的提出，克服了梯度消失的问题，神经网络可以做的非常深，从此进入了深度学习时代。深度神经网络提供了极强的抽象建模能力，对于各种任务特别是图像有着非常强大的识别能力。



支持向量机：

支持向量机（SVM）是90年代中期发展起来的基于统计学习理论的一种机器学习方法，通过寻求结构化风险最小来提高学习机泛化能力，实现经验风险和置信范围的最小化，从而达到在统计样本量较少的情况下，亦能获得良好统计规律的目的。

给定一组训练实例，每个训练实例被标记为属于两个类别中的一个或另一个，SVM训练算法建立一个将新的实例分配给两个类别之一的模型，使其成为非概率二元线性分类器。SVM模型是将实例表示为空间中的点，这样映射就使得单独类别的实例被尽可能宽的明显的间隔分开。然后，将新的实例映射到同一空间，并基于它们落在间隔的哪一侧来预测所属类别。

通俗来讲，它是一种二类分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，即支持向量机的学习策略便是间隔最大化，最终可转化为一个凸二次规划问题的求解。

对于非线性问题，SVM可以通过核技巧，选择一个合适的核函数来将样本非线性映射至高维特征空间，求解用来分类的超平面。

对于文字识别任务来说，SVM能在高维特征空间中灵活判别边界，并直接指明类边界的不同值，比以贝叶斯判别分类器为基础的识别方法更有优势。相比较欧式距离分类器，SVM在小规模分类中显示出较强的分类能力，也可被应用于相似字的识别。目前基于SVM的文字识别方法整体识别水平较高。但SVM仍存在一些问题，如对特征空间要求较高、对非线性问题没有通用解决方案，对大字符集的识别效率较低等，需要进一步的改进。



多方法聚合：

在目前的文字识别实践中，不管如何处理数据，构建模型，单个分类器的识别效果总是有其局限性，并且每种分类器都有不同的缺点，在特征不同样本上的表现会出现较大的波动。所以，研究者开始研究将多种分类器相结合的识别方法，又称为集成学习。一般地，对分类器的聚合分为两种方式：平行结构与串行结构。在平行结构中，各分类器进行独立的样本训练。串行结构中后端分类器主要是对前端训练不成功的样本进行再识别。聚合可以是多个相同类型分类器的聚合，也可以是不同分类器的聚合。



中国文字识别产业情况：

中国的文字识别产业起步较其他国家晚很多，在汉字识别领域，反而是日本学者在早期做了很多工作。其中有代表性的系统有1977年东芝综合研究所研制的可以识别2000汉字的单体印刷汉字识别系统；80年代初期，日本武藏野电气研究所研制的可以识别2300个多体汉字的印刷体汉字识别系统，代表了当时汉字识别的最高水平。

直到1986年，国家863计划信息领域课题组织了清华大学、北京信息工程学院、沈阳自动化所三家单位联合进行中文OCR软件的开发工作。1989年，清华大学率先推出了国内第一套中文OCR软件--清华文通TH-OCR1.0版。至此，中文OCR正式从实验室走向了市场。

清华OCR印刷体汉字识别软件其后又推出了TH-OCR 92高性能实用简／繁体、多字体、多功能印刷汉字识别系统，使印刷体汉字识别技术又取得重大进展。到1994年推出的TH-OCR 94高性能汉英混排印刷文本识别系统，则被专家鉴定为“是国内外首次推出的汉英混排印刷文本识别系统，总体上居国际领先水平”。上个世纪90年代中后期，清华大学电子工程系提出并进行了汉字识别综合研究，使汉字识别技术在印刷体文本、联机手写汉字识别、脱机手写汉字识别和脱机手写数字符号识别等领域全面地取得了重要成果。具有代表性的成果是TH-OCR 97综合集成汉字识别系统，它可以完成多文种(汉、英、日)印刷文本、联机手写汉字、脱机手写汉字和手写数字的识别输入。

1998年，汉王公司成立，汉王经过多年艰苦的自主创新，在光学文字识别多项关键技术取得突破的同时，成功开发出多个面向行业及通用市场的产品，这些产品都成为名牌产品，市场份额均居领先地位，在办公自动化、银行、税务、数字图书馆、邮政分拣等行业得到了广泛应用，同时带动了扫描仪、智能手机等相关行业的发展。

汉王OCR的项目成果使我国的OCR技术及应用走到了世界的前列,尽管IBM、HP、日立、东芝、夏普、NEC、理光等国外公司曾经巨额投入该领域，但是汉王的技术领先性迫使他们退出了竞争。

汉王OCR的技术路线是先突破关键技术，同时重视软硬件的有机结合，然后面向用户推出实用化的应用系统。从实施效果来看，这种思路非常适合现阶段我国软件产业的现状，并为推动我国自主知识产权软件的发展壮大做了有益的探索。

进入新世纪，随着互联网产业的逐渐崛起，特别是深度学习、大数据带来的技术红利的加持下，新兴互联网公司开始涉足文字识别产业。以百度公司旗下百度云为例，仅其提供的在线实时文字识别服务就有通用文字识别、网络图片识别、卡证识别、营业执照识别、车牌识别、票据识别、表格文字识别7个子项。甚至还可以根据大客户需求对识别的模型进行专门定制。

云技术的普及让更多人享受到了文字识别技术带来的红利，特别在新一代互联网服务的要求和政策形势下，应用于金融保险、社保、O2O等行业的用户证件信息的自动录入，身份验证等风控服务。以及内容服务中所需的内容审核与监管需求，如从图片、视频等多媒体中实时识别出，涉黄、涉暴、政治敏感、恶意广告等不合规内容，以规避业务风险，且大幅节约了人工审核成本。