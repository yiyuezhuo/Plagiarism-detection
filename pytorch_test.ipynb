{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_seq = torch.randn(20,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1178,  0.6974,  0.3317, -1.5489,  1.7258],\n",
       "        [-1.6983,  0.0571,  1.0761, -0.9370, -0.0728],\n",
       "        [ 0.0167,  0.7060, -0.8473,  1.7103, -0.2992],\n",
       "        [-1.3477, -1.1205,  0.8219, -1.0260, -0.1550],\n",
       "        [-1.1963, -0.2946, -0.3406, -1.5448, -0.8546],\n",
       "        [-0.0034, -1.6447,  0.3536,  0.6514, -0.5334],\n",
       "        [ 0.9225, -1.5803, -0.4260,  0.0374, -1.2610],\n",
       "        [ 1.1278,  0.2030, -1.1835, -0.6342,  0.4107],\n",
       "        [-0.2629, -1.1219,  0.8876,  0.9207, -0.6915],\n",
       "        [-1.9146, -0.5393,  0.4731,  0.8181, -0.6927],\n",
       "        [ 1.3584, -1.0825, -0.7219, -0.2689, -1.9217],\n",
       "        [-0.1313,  0.5677,  1.3095, -0.4247, -2.5669],\n",
       "        [ 0.9901, -1.0375, -1.0113, -0.0737,  1.1509],\n",
       "        [-1.3734,  0.6485, -0.2309,  1.5850,  0.5285],\n",
       "        [-0.8151,  0.1861, -1.1545,  2.1413, -1.1514],\n",
       "        [ 0.6874,  0.5364,  0.9465, -0.8875, -0.0218],\n",
       "        [ 1.0845,  1.5818,  1.2209,  0.1913, -0.1972],\n",
       "        [ 1.1928,  0.9025,  0.1889, -0.4885,  0.1036],\n",
       "        [ 0.2435,  0.5053,  0.4939,  1.4252,  1.3154],\n",
       "        [ 0.9628, -0.4753, -0.9217, -1.1387, -0.5754]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv1 = nn.Conv1d(5, 4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[-0.0464, -0.0211, -0.1917],\n",
       "          [-0.0735, -0.1753, -0.1654],\n",
       "          [ 0.1133,  0.1441,  0.0713],\n",
       "          [ 0.2496,  0.0801, -0.1862],\n",
       "          [-0.2355, -0.2356, -0.2059]],\n",
       " \n",
       "         [[ 0.1150, -0.1785, -0.1576],\n",
       "          [-0.1370,  0.1081, -0.1956],\n",
       "          [ 0.0371, -0.0190, -0.1188],\n",
       "          [-0.2198, -0.1322,  0.1014],\n",
       "          [ 0.1671,  0.1161,  0.2557]],\n",
       " \n",
       "         [[ 0.1957, -0.0978, -0.0660],\n",
       "          [ 0.1532, -0.2031, -0.1964],\n",
       "          [-0.2421,  0.0702,  0.2486],\n",
       "          [-0.0315, -0.2399,  0.1663],\n",
       "          [-0.0529, -0.1911, -0.1765]],\n",
       " \n",
       "         [[-0.0689,  0.0169, -0.1938],\n",
       "          [ 0.1249,  0.0672, -0.1173],\n",
       "          [-0.0577, -0.1353,  0.1382],\n",
       "          [-0.0589,  0.1761,  0.0110],\n",
       "          [-0.0192,  0.0180, -0.1651]]]), Parameter containing:\n",
       " tensor([ 0.0069,  0.1292,  0.1128, -0.2523])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(conv1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_seq.shape # L, C_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the simplest case, the output value of the layer with input size\n",
    "$(N, C_{in}, L)$ and output $(N, C_{out}, L_{out})$ can be\n",
    "precisely described as:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 20])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq = torch.unsqueeze(test_seq.transpose(0,1),0)\n",
    "input_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 18])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_seq = conv1(input_seq)\n",
    "out_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_pool = torch.nn.MaxPool1d(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 6])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_seq = max_pool(out_seq)\n",
    "pooled_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_pool2 = torch.nn.MaxPool1d(3, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 16])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_seq2 = max_pool2(out_seq)\n",
    "pooled_seq2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(10,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 300]), torch.Size([2, 3, 300]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_embed1 = embedding(torch.tensor([1,2,3]))\n",
    "out_embed2 = embedding(torch.tensor([[1,2,3],[4,5,6]]))\n",
    "out_embed1.shape, out_embed2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.randn(2,3), torch.randn(2,3)],0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1DText(nn.Module):\n",
    "    def __init__(self, embed_num = 259922, embed_dim = 300, class_num = 2, kernel_num = 100, kernel_sizes = (3,4,5),\n",
    "                dropout = 0.5):\n",
    "        super(CNN1DText, self).__init__()\n",
    "        \n",
    "        self.embed_num = embed_num\n",
    "        self.embed_dim = embed_dim\n",
    "        self.class_num = class_num\n",
    "        self.kernel_num = kernel_num\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        \n",
    "        min_size = max(kernel_sizes)\n",
    "        self.pad_sizes = [((size - min_size)//2 + (size -min_size)%2 , (size -min_size)//2)  for size in kernel_sizes]\n",
    "        \n",
    "        self.embed = nn.Embedding(embed_num, embed_dim)\n",
    "        self.convs = nn.ModuleList([nn.Conv1d(embed_dim, kernel_num, kernel_size) for kernel_size in kernel_sizes])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(kernel_num * len(kernel_sizes), class_num) # fake fc\n",
    "    def batch_forward(self, x):\n",
    "        # x (L)\n",
    "        x = self.embed(x) # (L, embed_dim)\n",
    "        x = torch.unsqueeze(x.transpose(0,1),0) # (1, embed_dim, L)\n",
    "        x = [conv(x) for conv in self.convs] # [(1, kernel_num, L'), (1, kernel_num, L''), ...]\n",
    "        x = [F.pad(torch.squeeze(x[i], 0), self.pad_sizes[i]) for i in range(len(x))] # [(kernel_num, L'),...]\n",
    "        x = torch.cat(x,0) # (len(kernel_sizes)*kernel_num, L')\n",
    "        x = x.transpose(0,1) # L', kernel_num, len(kernel_sizes) \n",
    "        x = self.fc(x) # (L', class_num)\n",
    "        return x # logit. softmax(x) = probability output \n",
    "    def forward(self, x):\n",
    "        # add and remove the extra N=1 dummy dimention to leverage other procedure which can only handle such form, \n",
    "        # such as those traning algorithm.\n",
    "        # (1, L)\n",
    "        x = self.batch_forward(torch.squeeze(x,0))\n",
    "        return torch.unsqueeze(torch.max(x,0)[0],0) #(1, class_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN1DText(embed_num = 259922, embed_dim = 300, class_num = 2, kernel_num = 100, kernel_sizes = (3,4,5),\n",
    "                dropout = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fake_input = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(fake_input,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2715,  0.1266]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.unsqueeze(fake_input,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5362,  0.4638]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(model(fake_input), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2364,  0.0367],\n",
       "        [ 0.2715,  0.1266],\n",
       "        [ 0.0579, -0.4812],\n",
       "        [ 0.1000, -0.5245],\n",
       "        [-0.1228,  0.1191],\n",
       "        [ 0.2532,  0.0634],\n",
       "        [ 0.0963,  0.1197]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.batch_forward(fake_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5498,  0.4502],\n",
       "        [ 0.5362,  0.4638],\n",
       "        [ 0.6316,  0.3684],\n",
       "        [ 0.6512,  0.3488],\n",
       "        [ 0.4398,  0.5602],\n",
       "        [ 0.5473,  0.4527],\n",
       "        [ 0.4941,  0.5059]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(model.batch_forward(fake_input), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
